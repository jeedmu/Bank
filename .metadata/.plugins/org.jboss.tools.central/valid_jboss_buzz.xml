<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Guru Night at Red Hat Summit: Hands-on experience with serverless computing</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/FIFSqs_vM7I/" /><category term="Containers" /><category term="Java" /><category term="Knative" /><category term="Kubernetes" /><category term="Quarkus" /><category term="Red Hat Summit" /><category term="Serverless" /><category term="apache camel" /><category term="Apache Kafka" /><category term="istio" /><category term="serverless computing" /><author><name>Doug Tidwell</name></author><id>https://developers.redhat.com/blog/?p=589977</id><updated>2019-04-26T07:05:32Z</updated><published>2019-04-26T07:05:32Z</published><content type="html">&lt;p&gt;Millions of developers worldwide want to learn more about serverless computing. If you&amp;#8217;re one of the lucky thousands attending &lt;a href="https://www.redhat.com/en/summit/2019"&gt;Red Hat Summit in Boston&lt;/a&gt; May 7-9, you can gain hands-on experience with the help of Burr Sutter and the Red Hat Developer team.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.redhat.com/it/engage/summit-guru-night-workshop-e-20190410"&gt;Guru Night is a BYOL (bring your own laptop) event&lt;/a&gt; taking place Wednesday, May 8 from 5:00 p.m. to 8:00 p.m. at the Boston Convention and Event Center in ML2 East-258AB.&lt;/strong&gt; (Doubtless there will be a map to show you where or what ML2 East etc. is; we have no idea.) &lt;a href="https://www.redhat.com/en/engage/summit-guru-night-workshop-e-20190410"&gt;Head to the signup page and fill out your details now.&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;TL;DR: Beer and pizza will be served.&lt;/h2&gt; &lt;p&gt;We felt compelled to point that out. But read on.&lt;/p&gt; &lt;p&gt;&lt;span id="more-589977"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;The details&lt;/h2&gt; &lt;p&gt;Although most of us would attend a serverless workshop sight unseen, here&amp;#8217;s more information that may help you decide to sign up. In this three-hour, hands-on workshop, designed specifically for software developers and architects, Burr and team will cover:&lt;/p&gt; &lt;h3&gt;&lt;a href="https://istio.io"&gt;Istio&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Istio brings an array of powerful features to the basic Kubernetes platform, including sidecar proxies and a service mesh for smarter canary deployments and dark launches. (Check out &lt;a href="https://developers.redhat.com/blog/2018/03/06/introduction-istio-makes-mesh-things/"&gt;Don Schenck&amp;#8217;s series of Istio blog posts&lt;/a&gt; for a great overview of the technology, how it works, and what it does.)&lt;/p&gt; &lt;h3&gt;&lt;a href="https://cloud.google.com/knative/"&gt;Knative&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Knative is the heart of the serverless infrastructure you&amp;#8217;ll use. Built on Istio and Kubernetes, it provides scale-to-zero support for services that aren&amp;#8217;t currently in demand. In addition, it can autoscale services in response to events and build container images inside the Kubernetes cluster. (Our friend Kamesh Sampath has &lt;a href="http://bit.ly/knative-tutorial"&gt;an excellent Knative tutorial&lt;/a&gt; that&amp;#8217;s not to be missed.)&lt;/p&gt; &lt;h3&gt;&lt;a href="https://quarkus.io"&gt;Quarkus&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Anxious that your hard-earned Java skills may not be as useful in the world of containers, microservices, and serverless computing? Worry not. Quarkus is a revolutionary technology that optimizes Java for those environments, delivering a performance improvement of 10x to 100x in many cases. It&amp;#8217;s supersonic, subatomic Java.&lt;/p&gt; &lt;h3&gt;&lt;a href="https://camel.apache.org/staging/camel-k/latest/index.html"&gt;Apache Camel K&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Camel K is built on Camel&amp;#8217;s event-driven architecture. It is a lightweight integration framework that runs natively on OpenShift or Kubernetes that is specifically designed for serverless computing and microservices. Check out &lt;a href="https://medium.com/@davsclaus/announcing-apache-camel-k-eef577cbee5a"&gt;an introduction to the platform itself&lt;/a&gt; and &lt;a href="https://www.nicolaferraro.me/2018/12/10/camel-k-on-knative/"&gt;an article on how Camel K works with Knative&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;&lt;a href="http://kafka.apache.org"&gt;Apache Kafka&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Data pipelines and event streams are a vital part of many modern applications. The Kafka website describes it as &amp;#8220;wicked fast.&amp;#8221; It&amp;#8217;s an established technology, and it runs in production in thousands of enterprises today.&lt;/p&gt; &lt;h2&gt;Sign up now&lt;/h2&gt; &lt;p&gt;Want hands-on experience with these cutting-edge technologies? Yah, you betcha. &lt;strong&gt;&lt;a href="https://www.redhat.com/en/engage/summit-guru-night-workshop-e-20190410"&gt;Sign up now.&lt;/a&gt; &lt;/strong&gt;&lt;/p&gt; &lt;p&gt;As you would expect, you must be a registered Red Hat Summit attendee to attend this session. If you haven’t registered yet, visit &lt;a href="https://www.redhat.com/en/summit/2019/?intcmp=701f20000012i8UAAQ"&gt;Red Hat Summit&lt;/a&gt; to sign up. See you in Boston!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Fguru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing%2F&amp;#38;linkname=Guru%20Night%20at%20Red%20Hat%20Summit%3A%20Hands-on%20experience%20with%20serverless%20computing" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Fguru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing%2F&amp;#38;linkname=Guru%20Night%20at%20Red%20Hat%20Summit%3A%20Hands-on%20experience%20with%20serverless%20computing" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Fguru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing%2F&amp;#38;linkname=Guru%20Night%20at%20Red%20Hat%20Summit%3A%20Hands-on%20experience%20with%20serverless%20computing" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Fguru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing%2F&amp;#38;linkname=Guru%20Night%20at%20Red%20Hat%20Summit%3A%20Hands-on%20experience%20with%20serverless%20computing" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Fguru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing%2F&amp;#38;linkname=Guru%20Night%20at%20Red%20Hat%20Summit%3A%20Hands-on%20experience%20with%20serverless%20computing" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Fguru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing%2F&amp;#38;linkname=Guru%20Night%20at%20Red%20Hat%20Summit%3A%20Hands-on%20experience%20with%20serverless%20computing" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Fguru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing%2F&amp;#38;linkname=Guru%20Night%20at%20Red%20Hat%20Summit%3A%20Hands-on%20experience%20with%20serverless%20computing" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Fguru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing%2F&amp;#38;linkname=Guru%20Night%20at%20Red%20Hat%20Summit%3A%20Hands-on%20experience%20with%20serverless%20computing" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Fguru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing%2F&amp;#038;title=Guru%20Night%20at%20Red%20Hat%20Summit%3A%20Hands-on%20experience%20with%20serverless%20computing" data-a2a-url="https://developers.redhat.com/blog/2019/04/26/guru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing/" data-a2a-title="Guru Night at Red Hat Summit: Hands-on experience with serverless computing"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/26/guru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing/"&gt;Guru Night at Red Hat Summit: Hands-on experience with serverless computing&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/FIFSqs_vM7I" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Millions of developers worldwide want to learn more about serverless computing. If you&amp;#8217;re one of the lucky thousands attending Red Hat Summit in Boston May 7-9, you can gain hands-on experience with the help of Burr Sutter and the Red Hat Developer team. Guru Night is a BYOL (bring your own laptop) event taking place [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/26/guru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing/"&gt;Guru Night at Red Hat Summit: Hands-on experience with serverless computing&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2019/04/26/guru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">589977</post-id><dc:creator>Doug Tidwell</dc:creator><dc:date>2019-04-26T07:05:32Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/26/guru-night-at-red-hat-summit-hands-on-experience-with-serverless-computing/</feedburner:origLink></entry><entry><title>Optimizing Red Hat Fuse 7 Spring Boot container images</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/fQmW978edCE/" /><category term="Containers" /><category term="Java" /><category term="JBoss Fuse" /><category term="Red Hat OpenShift Container Platform" /><category term="Spring Boot" /><category term="containers" /><category term="Fuse" /><category term="Integration" /><category term="Red Hat OpenShift" /><author><name>Roman Martin Gil</name></author><id>https://developers.redhat.com/blog/?p=584747</id><updated>2019-04-26T07:00:47Z</updated><published>2019-04-26T07:00:47Z</published><content type="html">&lt;p&gt;Working with &lt;a href="https://developers.redhat.com/products/fuse/overview"&gt;Red Hat Fuse 7&lt;/a&gt; on Spring Boot is straightforward. In my field experience, I have seen many development (a.k.a. integrator) teams moving to Fuse 7 on Spring Boot for their new integration platforms on Red Hat OpenShift Container Platform (well aligned with &lt;a href="https://middlewareblog.redhat.com/2017/09/13/what-is-agile-integration/"&gt;agile integration&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;Lately, however, I have also seen some teams worried about the size of the final images and the deployment pipeline. In most cases, they had developed a set of common libraries or frameworks to extend or to homogenize the final integration projects. All the cases have the same result:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Several dependencies copied in each integration project&lt;/li&gt; &lt;li&gt;Always replacing the container images with the latest fat JAR (including the same dependencies) in each build pipeline&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/26/spring-boot-red-hat-openshift-application-runtimes/"&gt;Spring Boot&lt;/a&gt; is usually packaged as &amp;#8220;fat JARS&amp;#8221; that contain all runtime dependencies. Although this is quite convenient, because you only need a JRE and a single JAR to run the application, in a container environment such as Red Hat OpenShift, you have to build a full container image to deploy your application.&lt;/p&gt; &lt;p&gt;&lt;span id="more-584747"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Single application layer vs. multiple application layer&lt;/h2&gt; &lt;p&gt;A typical container image with Fuse 7 on Spring Boot application has the following structure:&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-588977 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/04/fuse7-sb-fatjar.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/04/fuse7-sb-fatjar.png" alt="Fuse 7 Container Image as Fat JAR" width="300" height="203" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/04/fuse7-sb-fatjar.png 814w, https://developers.redhat.com/blog/wp-content/uploads/2019/04/fuse7-sb-fatjar-300x203.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/04/fuse7-sb-fatjar-768x520.png 768w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;Basically, the image has only two big layers:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Fuse 7 on Spring Boot Application: Fat JAR created by Fuse 7 with Spring Boot and all its dependencies&lt;/li&gt; &lt;li&gt;Java Runtime: Base image providing the JRE and other libraries, tools, and so on.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Every time the application is built with this structure, we are wasting the storage of that layer. Basically, the container image build process will not reuse the cache of that layer because we are adding a new fat JAR, which may be very similar to the previous one because normally we are doing small changes in our application.&lt;/p&gt; &lt;p&gt;One of the best practices of Dockerfiles is reducing the number of layers; however, in our case, we should also minimize the size of the layers we are changing between each build. Applications developed with Fuse 7 on Spring Boot will change a few things (Camel Routes, Beans, etc.); however, the dependencies used are basically the same for each build process.&lt;/p&gt; &lt;p&gt;To optimize the storage and increase the build process and the deployment phase, we need to change the default structure. The new structure should be similar to:&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-588967 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/04/fuse7-sb-thinjar.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/04/fuse7-sb-thinjar.png" alt="Fuse 7 Container Image as Thin JAR" width="300" height="299" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/04/fuse7-sb-thinjar.png 806w, https://developers.redhat.com/blog/wp-content/uploads/2019/04/fuse7-sb-thinjar-150x150.png 150w, https://developers.redhat.com/blog/wp-content/uploads/2019/04/fuse7-sb-thinjar-300x300.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/04/fuse7-sb-thinjar-768x766.png 768w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;This new structure is based on three layers:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Application: This only has the final application. The components could be changed several times, but the layer is small because it only includes the items needed for the application (Apache Camel context basically).&lt;/li&gt; &lt;li&gt;Spring Boot and dependencies: Any dependency or library needed by the application will be managed in this layer. It is bigger than the previous one, but this layer will change only if we apply changes in the dependency tree of the application.&lt;/li&gt; &lt;li&gt;Java Runtime: Base image providing the JRE and other libraries, tools, and so on.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To achieve this, there are other strategies, such as Docker multistage build; however, this article is based in Maven and its life cycle.&lt;/p&gt; &lt;p&gt;The main steps are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;To not package the application as Spring Boot does (i.e., not use &lt;i&gt;spring-boot-maven-plugin&lt;/i&gt;)&lt;/li&gt; &lt;li&gt;Use Maven plugins to copy any &lt;i&gt;runtime&lt;/i&gt; dependency needed by the application in one place&lt;/li&gt; &lt;li&gt;Use Maven plugins to build a simple jar file with the classes provided by the application. This new application will include a MANIFEST.MF file with: &lt;ul&gt; &lt;li&gt;Main class name&lt;/li&gt; &lt;li&gt;Class-Path entry to locate any dependency needed by the application.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Build container image using a Dockerfile aligned with the new layer structure: &lt;ul&gt; &lt;li&gt;From a base image providing OS and Java Runtime&lt;/li&gt; &lt;li&gt;Copy any dependency needed by the application into a one place&lt;/li&gt; &lt;li&gt;Copy application file (JAR file) in a place to be executed&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Show me the code&lt;/h2&gt; &lt;p&gt;There is a single project developed in GitHub to &lt;a href="https://github.com/rmarting/fuse7-sb-sample-docker-fatjar-vs-docker-thinjar"&gt;show how to implement this strategy easily.&lt;/a&gt; This project includes two different Maven profiles to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Build a Fat JAR file (fuse7-sb-fatjar): Typical Fuse 7 on Spring Boot Application&lt;/li&gt; &lt;li&gt;Build a Thin JAR file (fuse7-sb-thinjar): Fuse 7 on Spring Boot application using the new structure&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In both cases, the &lt;a href="https://dmp.fabric8.io/"&gt;&lt;i&gt;docker-maven-plugin&lt;/i&gt;&lt;/a&gt; is used to build the container image. Also the base image to build the image is the same, the official image provided by Red Hat for Fuse 7 Spring Boot applications (&lt;a href="https://access.redhat.com/containers/?tab=overview#/registry.access.redhat.com/fuse7/fuse-java-openshift"&gt;fuse7/fuse-java-openshift:1.2&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;The profile to build a fat JAR is:&lt;/p&gt; &lt;pre&gt;&amp;#60;profile&amp;#62; &amp;#60;id&amp;#62;fuse7-sb-fatjar&amp;#60;/id&amp;#62; &amp;#60;activation&amp;#62; &amp;#60;activeByDefault&amp;#62;false&amp;#60;/activeByDefault&amp;#62; &amp;#60;/activation&amp;#62; &amp;#60;build&amp;#62; &amp;#60;defaultGoal&amp;#62;spring-boot:run&amp;#60;/defaultGoal&amp;#62; &amp;#60;plugins&amp;#62; &amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;org.jboss.redhat-fuse&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;spring-boot-maven-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;executions&amp;#62; &amp;#60;execution&amp;#62; &amp;#60;goals&amp;#62; &amp;#60;goal&amp;#62;repackage&amp;#60;/goal&amp;#62; &amp;#60;/goals&amp;#62; &amp;#60;/execution&amp;#62; &amp;#60;/executions&amp;#62; &amp;#60;/plugin&amp;#62; &amp;#60;!-- Build Docker Image --&amp;#62; &amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;io.fabric8&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;docker-maven-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;executions&amp;#62; &amp;#60;!-- Build Docker Image at Maven package phase --&amp;#62; &amp;#60;execution&amp;#62; &amp;#60;id&amp;#62;docker&amp;#60;/id&amp;#62; &amp;#60;phase&amp;#62;package&amp;#60;/phase&amp;#62; &amp;#60;goals&amp;#62; &amp;#60;goal&amp;#62;build&amp;#60;/goal&amp;#62; &amp;#60;/goals&amp;#62; &amp;#60;/execution&amp;#62; &amp;#60;/executions&amp;#62; &amp;#60;configuration&amp;#62; &amp;#60;images&amp;#62; &amp;#60;image&amp;#62; &amp;#60;name&amp;#62;fuse7-sb-sample-fatjar:${project.version}&amp;#60;/name&amp;#62; &amp;#60;build&amp;#62; &amp;#60;from&amp;#62;registry.access.redhat.com/fuse7/fuse-java-openshift:1.2&amp;#60;/from&amp;#62; &amp;#60;assembly&amp;#62; &amp;#60;basedir&amp;#62;/deployments&amp;#60;/basedir&amp;#62; &amp;#60;descriptorRef&amp;#62;artifact&amp;#60;/descriptorRef&amp;#62; &amp;#60;/assembly&amp;#62; &amp;#60;/build&amp;#62; &amp;#60;/image&amp;#62; &amp;#60;/images&amp;#62; &amp;#60;/configuration&amp;#62; &amp;#60;/plugin&amp;#62; &amp;#60;/plugins&amp;#62; &amp;#60;/build&amp;#62; &amp;#60;/profile&amp;#62;&lt;/pre&gt; &lt;p&gt;To build the project as usual with Fuse 7 on Spring Boot application:&lt;/p&gt; &lt;pre&gt;$ mvn clean package -Pfuse7-sb-fatjar&lt;/pre&gt; &lt;p&gt;The container image and its structure could be inspected as:&lt;/p&gt; &lt;pre&gt;$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE fuse7-sb-sample-fatjar 1.0.0-SNAPSHOT 413ec90066b2 2 minutes ago 472MB $ docker image history fuse7-sb-sample-fatjar:1.0.0-SNAPSHOT IMAGE CREATED CREATED BY SIZE 413ec90066b2 3 minutes ago /bin/sh -c #(nop) COPY dir:bce1849c62a66a19b… 22.5MB 3acce9532a02 2 months ago 29.7MB &amp;#60;missing&amp;#62; 2 months ago 204MB &amp;#60;missing&amp;#62; 2 months ago 12.6MB &amp;#60;missing&amp;#62; 2 months ago 2.92kB &amp;#60;missing&amp;#62; 2 months ago 203MB&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Application layer consumes 22.5 MB of storage.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The profile to build a thin JAR is:&lt;/p&gt; &lt;pre&gt;&amp;#60;profile&amp;#62; &amp;#60;id&amp;#62;fuse7-sb-thinjar&amp;#60;/id&amp;#62; &amp;#60;activation&amp;#62; &amp;#60;activeByDefault&amp;#62;false&amp;#60;/activeByDefault&amp;#62; &amp;#60;/activation&amp;#62; &amp;#60;build&amp;#62; &amp;#60;plugins&amp;#62; &amp;#60;!-- Generate a simple JAR file with ClassPath --&amp;#62; &amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;org.apache.maven.plugins&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;maven-dependency-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;executions&amp;#62; &amp;#60;execution&amp;#62; &amp;#60;id&amp;#62;copy-dependencies&amp;#60;/id&amp;#62; &amp;#60;goals&amp;#62; &amp;#60;goal&amp;#62;copy-dependencies&amp;#60;/goal&amp;#62; &amp;#60;/goals&amp;#62; &amp;#60;configuration&amp;#62; &amp;#60;outputDirectory&amp;#62;${project.build.directory}/lib&amp;#60;/outputDirectory&amp;#62; &amp;#60;includeScope&amp;#62;runtime&amp;#60;/includeScope&amp;#62; &amp;#60;/configuration&amp;#62; &amp;#60;/execution&amp;#62; &amp;#60;/executions&amp;#62; &amp;#60;/plugin&amp;#62; &amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;org.apache.maven.plugins&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;maven-jar-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;configuration&amp;#62; &amp;#60;archive&amp;#62; &amp;#60;manifest&amp;#62; &amp;#60;addClasspath&amp;#62;true&amp;#60;/addClasspath&amp;#62; &amp;#60;classpathPrefix&amp;#62;lib/&amp;#60;/classpathPrefix&amp;#62; &amp;#60;mainClass&amp;#62;org.jboss.fuse7.samples.Application&amp;#60;/mainClass&amp;#62; &amp;#60;/manifest&amp;#62; &amp;#60;/archive&amp;#62; &amp;#60;/configuration&amp;#62; &amp;#60;/plugin&amp;#62; &amp;#60;!-- Build Docker Image --&amp;#62; &amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;io.fabric8&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;docker-maven-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;executions&amp;#62; &amp;#60;!-- Build Docker Image at Maven package phase --&amp;#62; &amp;#60;execution&amp;#62; &amp;#60;id&amp;#62;docker&amp;#60;/id&amp;#62; &amp;#60;phase&amp;#62;package&amp;#60;/phase&amp;#62; &amp;#60;goals&amp;#62; &amp;#60;goal&amp;#62;build&amp;#60;/goal&amp;#62; &amp;#60;/goals&amp;#62; &amp;#60;/execution&amp;#62; &amp;#60;/executions&amp;#62; &amp;#60;configuration&amp;#62; &amp;#60;images&amp;#62; &amp;#60;image&amp;#62; &amp;#60;name&amp;#62;fuse7-sb-sample-thinjar:${project.version}&amp;#60;/name&amp;#62; &amp;#60;build&amp;#62; &amp;#60;dockerFile&amp;#62;${project.basedir}/Dockerfile&amp;#60;/dockerFile&amp;#62; &amp;#60;/build&amp;#62; &amp;#60;/image&amp;#62; &amp;#60;/images&amp;#62; &amp;#60;/configuration&amp;#62; &amp;#60;/plugin&amp;#62; &amp;#60;/plugins&amp;#62; &amp;#60;/build&amp;#62; &amp;#60;/profile&amp;#62;&lt;/pre&gt; &lt;p&gt;This profile uses a new Dockerfile to define the new structure.&lt;/p&gt; &lt;pre&gt;FROM registry.access.redhat.com/fuse7/fuse-java-openshift:1.2 # Fuse 7, Spring Boot and Third Party Dependencies COPY target/lib /deployments/lib # Application COPY target/*.jar /deployments&lt;/pre&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;To build the project with the new structure:&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;$ mvn clean package -Pfuse7-sb-thinjar&lt;/pre&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;The container image and its structure could be inspected as:&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE fuse7-sb-sample-fatjar 1.0.0-SNAPSHOT 413ec90066b2 2 minutes ago 472MB fuse7-sb-sample-thinjar 1.0.0-SNAPSHOT f3bf83f4ac28 About a minute ago 472MB $ docker image history fuse7-sb-sample-thinjar:1.0.0-SNAPSHOT IMAGE CREATED CREATED BY SIZE f3bf83f4ac28 3 minutes ago /bin/sh -c #(nop) COPY file:8e8b28eec64eeef0… 5.93kB 8f85633e632f 6 weeks ago /bin/sh -c #(nop) COPY dir:9371efeba146b0c49… 22.4MB 3acce9532a02 2 months ago 29.7MB &amp;#60;missing&amp;#62; 2 months ago 204MB &amp;#60;missing&amp;#62; 2 months ago 12.6MB &amp;#60;missing&amp;#62; 2 months ago 2.92kB &amp;#60;missing&amp;#62; 2 months ago 203M&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Application layer only consumes around 6 kB of storage.&lt;/strong&gt;&lt;/p&gt; &lt;h3&gt;Conclusions&lt;/h3&gt; &lt;p&gt;Comparing both container images we could conclude:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Both images have the same final size (472 MB)&lt;/li&gt; &lt;li&gt;No changes or effects during application execution&lt;/li&gt; &lt;li&gt;After each build using the fat JAR application, the layer with the application is replaced completely (around 22 MB)&lt;/li&gt; &lt;li&gt;After each build using the thin JAR, only the application layer is replaced completely (around 6 kB). Docker cache layer is applied for dependencies.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;So, if you are worried about the size of your Fuse 7 on Spring Boot applications, there are various alternatives and strategies to help you optimize it.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Foptimizing-red-hat-fuse-7-spring-boot-container-images%2F&amp;#38;linkname=Optimizing%20Red%20Hat%20Fuse%207%20Spring%20Boot%20container%20images" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Foptimizing-red-hat-fuse-7-spring-boot-container-images%2F&amp;#38;linkname=Optimizing%20Red%20Hat%20Fuse%207%20Spring%20Boot%20container%20images" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Foptimizing-red-hat-fuse-7-spring-boot-container-images%2F&amp;#38;linkname=Optimizing%20Red%20Hat%20Fuse%207%20Spring%20Boot%20container%20images" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Foptimizing-red-hat-fuse-7-spring-boot-container-images%2F&amp;#38;linkname=Optimizing%20Red%20Hat%20Fuse%207%20Spring%20Boot%20container%20images" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Foptimizing-red-hat-fuse-7-spring-boot-container-images%2F&amp;#38;linkname=Optimizing%20Red%20Hat%20Fuse%207%20Spring%20Boot%20container%20images" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Foptimizing-red-hat-fuse-7-spring-boot-container-images%2F&amp;#38;linkname=Optimizing%20Red%20Hat%20Fuse%207%20Spring%20Boot%20container%20images" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Foptimizing-red-hat-fuse-7-spring-boot-container-images%2F&amp;#38;linkname=Optimizing%20Red%20Hat%20Fuse%207%20Spring%20Boot%20container%20images" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Foptimizing-red-hat-fuse-7-spring-boot-container-images%2F&amp;#38;linkname=Optimizing%20Red%20Hat%20Fuse%207%20Spring%20Boot%20container%20images" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F26%2Foptimizing-red-hat-fuse-7-spring-boot-container-images%2F&amp;#038;title=Optimizing%20Red%20Hat%20Fuse%207%20Spring%20Boot%20container%20images" data-a2a-url="https://developers.redhat.com/blog/2019/04/26/optimizing-red-hat-fuse-7-spring-boot-container-images/" data-a2a-title="Optimizing Red Hat Fuse 7 Spring Boot container images"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/26/optimizing-red-hat-fuse-7-spring-boot-container-images/"&gt;Optimizing Red Hat Fuse 7 Spring Boot container images&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/fQmW978edCE" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Working with Red Hat Fuse 7 on Spring Boot is straightforward. In my field experience, I have seen many development (a.k.a. integrator) teams moving to Fuse 7 on Spring Boot for their new integration platforms on Red Hat OpenShift Container Platform (well aligned with agile integration). Lately, however, I have also seen some teams worried [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/26/optimizing-red-hat-fuse-7-spring-boot-container-images/"&gt;Optimizing Red Hat Fuse 7 Spring Boot container images&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2019/04/26/optimizing-red-hat-fuse-7-spring-boot-container-images/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">584747</post-id><dc:creator>Roman Martin Gil</dc:creator><dc:date>2019-04-26T07:00:47Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/26/optimizing-red-hat-fuse-7-spring-boot-container-images/</feedburner:origLink></entry><entry><title>Podman basics cheat sheet</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/jmO7dVP8QUE/" /><category term="Containers" /><category term="Feature" /><category term="Red Hat Enterprise Linux" /><category term="Cheat Sheet" /><category term="Cheatsheet" /><category term="containers" /><category term="Docker" /><category term="Podman" /><author><name>Doug Tidwell</name></author><id>https://developers.redhat.com/blog/?p=587547</id><updated>2019-04-25T07:05:07Z</updated><published>2019-04-25T07:05:07Z</published><content type="html">&lt;p&gt;Here and elsewhere, we get a lot of questions about post-Docker container tools in Red Hat Enterprise Linux 7.6 and Red Hat Enterprise Linux 8 beta. Tools like &lt;a href="https://podman.io"&gt;podman&lt;/a&gt;, &lt;a href="https://buildah.io"&gt;buildah&lt;/a&gt;, and &lt;a href="https://github.com/containers/skopeo"&gt;skopeo&lt;/a&gt; enable you to create and manage &lt;em&gt;rootless containers&lt;/em&gt;, which are containers that don&amp;#8217;t require root access to be built and deployed. To help you master the basics, we&amp;#8217;re happy to offer a &lt;a href="https://developers.redhat.com/cheat-sheets/podman-basics/"&gt;new podman basics cheat sheet&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;span id="more-587547"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;The good news is that if you know basic Docker commands, you can usually simply replace &lt;code&gt;docker&lt;/code&gt; with &lt;code&gt;podman&lt;/code&gt; and do whatever you&amp;#8217;re used to doing. As a matter of fact, the two command-line interfaces are so similar that some users define &lt;a href="https://twitter.com/ialanmoran/status/1001671953571303425"&gt;alias docker=&amp;#8217;podman&amp;#8217;&lt;/a&gt;:&lt;/p&gt; &lt;p&gt;&lt;img class=" size-large wp-image-587747 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/04/docker-alias-1024x420.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/04/docker-alias-1024x420.png" alt="Defining docker as an alias for podman" width="640" height="263" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/04/docker-alias-1024x420.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/04/docker-alias-300x123.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/04/docker-alias-768x315.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/04/docker-alias.png 1252w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p&gt;In addition to &lt;a href="https://developers.redhat.com/cheat-sheets/podman-basics/"&gt;the podman basics cheat sheet,&lt;/a&gt; here are other resources that can help you get started with podman:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/08/29/intro-to-podman/"&gt;Intro to Podman&lt;/a&gt; by Alessandro Arrichiello&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/02/21/podman-and-buildah-for-docker-users/"&gt;Podman and Buildah for Docker users&lt;/a&gt; by William Henry&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/20/buildah-podman-containers-without-daemons/"&gt;Containers without daemons&lt;/a&gt; by Tom Sweeney&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/01/15/podman-managing-containers-pods/"&gt;Podman: Managing pods and containers in a local container runtime&lt;/a&gt; by Brent Baude&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/podman-next-generation-linux-container-tools/"&gt;Podman &amp;#8211; The next generation of Linux container tools&lt;/a&gt; by Doug Tidwell&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/cheat-sheets/podman-basics/"&gt;Download the podman basics cheat sheet now&lt;/a&gt; and have fun working with rootless containers!&lt;/p&gt; &lt;h3&gt;Also read&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/03/04/red-hat-enterprise-linux-8-beta-cheat-sheet-for-developers/"&gt;Red Hat Enterprise Linux 8 Beta cheat sheet&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/cheat-sheets/containers/"&gt;Containers cheat sheet&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/cheat-sheets/kubernetes/"&gt;Kubernetes cheat sheet&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fpodman-basics-cheat-sheet%2F&amp;#38;linkname=Podman%20basics%20cheat%20sheet" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fpodman-basics-cheat-sheet%2F&amp;#38;linkname=Podman%20basics%20cheat%20sheet" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fpodman-basics-cheat-sheet%2F&amp;#38;linkname=Podman%20basics%20cheat%20sheet" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fpodman-basics-cheat-sheet%2F&amp;#38;linkname=Podman%20basics%20cheat%20sheet" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fpodman-basics-cheat-sheet%2F&amp;#38;linkname=Podman%20basics%20cheat%20sheet" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fpodman-basics-cheat-sheet%2F&amp;#38;linkname=Podman%20basics%20cheat%20sheet" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fpodman-basics-cheat-sheet%2F&amp;#38;linkname=Podman%20basics%20cheat%20sheet" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fpodman-basics-cheat-sheet%2F&amp;#38;linkname=Podman%20basics%20cheat%20sheet" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fpodman-basics-cheat-sheet%2F&amp;#038;title=Podman%20basics%20cheat%20sheet" data-a2a-url="https://developers.redhat.com/blog/2019/04/25/podman-basics-cheat-sheet/" data-a2a-title="Podman basics cheat sheet"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/25/podman-basics-cheat-sheet/"&gt;Podman basics cheat sheet&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/jmO7dVP8QUE" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Here and elsewhere, we get a lot of questions about post-Docker container tools in Red Hat Enterprise Linux 7.6 and Red Hat Enterprise Linux 8 beta. Tools like podman, buildah, and skopeo enable you to create and manage rootless containers, which are containers that don&amp;#8217;t require root access to be built and deployed. To help you [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/25/podman-basics-cheat-sheet/"&gt;Podman basics cheat sheet&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2019/04/25/podman-basics-cheat-sheet/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">587547</post-id><dc:creator>Doug Tidwell</dc:creator><dc:date>2019-04-25T07:05:07Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/25/podman-basics-cheat-sheet/</feedburner:origLink></entry><entry><title>Red Hat CodeReady Workspaces 1.1: Release notes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/pTt9CkWTH9g/" /><category term="CodeReady Workspaces" /><category term="Containers" /><category term="containers" /><category term="Red Hat CodeReady Workspaces" /><author><name>Stevan LeMeur</name></author><id>https://developers.redhat.com/blog/?p=587017</id><updated>2019-04-25T07:05:02Z</updated><published>2019-04-25T07:05:02Z</published><content type="html">&lt;p&gt;We are pleased to introduce &lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;Red Hat CodeReady Workspaces&lt;/a&gt; version 1.1, which provides a cloud developer workspace server and browser-based IDE built for teams and organizations. Red Hat CodeReady Workspaces 1.1 includes ready-to-use developer stacks for most of the popular programming languages, frameworks, and Red Hat technologies.&lt;/p&gt; &lt;p&gt;This version of Red Hat CodeReady Workspaces introduces:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Compatibility with Red Hat OpenShift 4.0&lt;/li&gt; &lt;li&gt;Installation in disconnected environments&lt;/li&gt; &lt;li&gt;Simplified configuration of OpenShift OAuth and cluster certificates&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Red Hat CodeReady Workspaces 1.1 is available now in the &lt;a href="https://access.redhat.com/containers/"&gt;Red Hat Container Catalog&lt;/a&gt;. You can install it on OpenShift Container Platform or OpenShift Dedicated, starting at version 3.11, by following the instructions in the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/1.1/html/administration_guide/installing_codeready-workspaces"&gt;Administration Guide&lt;/a&gt;.&lt;span id="more-587017"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;For Red Hat OpenShift 4.0, CodeReady Workspaces 1.1 is available now in Developer Preview from the OperatorHub. Based on a new operator that leverages the Operator Lifecycle Manager, the installation flow is getting simpler and can be handled without leaving the OpenShift Console. If you already have Red Hat OpenShift 4.0, get Red Hat CodeReady Workspaces 1.1 from the OperatorHub and follow the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/1.1/html/administration_guide/installing_codeready-workspaces-from-operator-hub"&gt;dedicated documentation&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;New features in Red Hat CodeReady Workspaces 1.1&lt;/b&gt;&lt;/h2&gt; &lt;h3&gt;&lt;b&gt;Authenticate users using OpenShift OAuth &lt;/b&gt;&lt;/h3&gt; &lt;p&gt;To authenticate users, Red Hat CodeReady Workspaces can be configured to rely on OpenShift OAuth, so they will require only a single authentication to access the OpenShift console or CodeReady Workspaces.&lt;/p&gt; &lt;h3&gt;&lt;b&gt;Certificate configuration&lt;/b&gt;&lt;/h3&gt; &lt;p&gt;If you are deploying Red Hat CodeReady Workspaces onto a cluster configured with certificates (self-signed or public ones), the deployment will now automatically detect and configure those certificates for CodeReady Workspaces.&lt;/p&gt; &lt;h3&gt;&lt;b&gt;Disconnected installation&lt;/b&gt;&lt;/h3&gt; &lt;p&gt;Installing and updating Red Hat CodeReady Workspaces pulls images from the Red Hat Container Catalog. Configuring CodeReady Workspaces with your own container registries is now easier, which simplifies installation in disconnected or restricted environments.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;Red Hat OpenShift 4.0 Developer Preview&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;Red Hat CodeReady Workspaces is now compatible with Red Hat OpenShift 4.0 and gets a dedicated operator leveraging the Operator Lifecycle Manager. Now available in Developer Preview, CodeReady Workspaces can be installed from the OpenShift 4.0 Operator Hub.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;Operator Lifecycle Manager support for Red Hat CodeReady Workspaces&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://github.com/operator-framework/operator-sdk"&gt;Operator Lifecycle Manager&lt;/a&gt; (OLM) project is a component of the Operator Framework, an open source toolkit to manage Kubernetes-native applications, called Operators, in an effective, automated, and scalable way.&lt;/p&gt; &lt;p&gt;In Red Hat OpenShift Container Platform, OLM aids cluster administrators in installing, upgrading, and granting access to Operators running on their cluster. The OpenShift Container Platform web console also provides a marketplace where administrators can access a catalog of curated Operators, including the Red Hat supported Operators.&lt;/p&gt; &lt;p&gt;OLM enables users to do the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Define applications as a single Kubernetes resource that encapsulates requirements and metadata.&lt;/li&gt; &lt;li&gt;Install applications automatically with dependency resolution, or manually with nothing but kubectl.&lt;/li&gt; &lt;li&gt;Upgrade applications automatically with different approval policies.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Red Hat CodeReady Workspaces is now getting a Red Hat supported Operator that leverages the capabilities of OLM.&lt;br /&gt; You can learn more in the following video:&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/HwhkGYsgVqs?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;p&gt;If you already have OpenShift 4.0, get Red Hat CodeReady Workspaces 1.1 from the OperatorHub and follow the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/1.1/html/administration_guide/installing_codeready-workspaces-from-operator-hub"&gt;dedicated documentation&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;Documentation Improvements&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;This release also includes documentation for:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Authoring custom Workspace stacks&lt;/li&gt; &lt;li&gt;Installing in restricted environments&lt;/li&gt; &lt;li&gt;Tuning settings when running CRW with many workspaces&lt;/li&gt; &lt;li&gt;Using VCS in Red Hat CodeReady Workspaces&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;&lt;b&gt;Supported Environments&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;Red Hat CodeReady Workspaces for OpenShift can be installed on Red Hat Openshift Container Platform or OpenShift Dedicated starting at version 3.11.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fred-hat-codeready-workspaces-1-1-release-notes%2F&amp;#38;linkname=Red%20Hat%20CodeReady%20Workspaces%201.1%3A%20Release%20notes" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fred-hat-codeready-workspaces-1-1-release-notes%2F&amp;#38;linkname=Red%20Hat%20CodeReady%20Workspaces%201.1%3A%20Release%20notes" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fred-hat-codeready-workspaces-1-1-release-notes%2F&amp;#38;linkname=Red%20Hat%20CodeReady%20Workspaces%201.1%3A%20Release%20notes" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fred-hat-codeready-workspaces-1-1-release-notes%2F&amp;#38;linkname=Red%20Hat%20CodeReady%20Workspaces%201.1%3A%20Release%20notes" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fred-hat-codeready-workspaces-1-1-release-notes%2F&amp;#38;linkname=Red%20Hat%20CodeReady%20Workspaces%201.1%3A%20Release%20notes" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fred-hat-codeready-workspaces-1-1-release-notes%2F&amp;#38;linkname=Red%20Hat%20CodeReady%20Workspaces%201.1%3A%20Release%20notes" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fred-hat-codeready-workspaces-1-1-release-notes%2F&amp;#38;linkname=Red%20Hat%20CodeReady%20Workspaces%201.1%3A%20Release%20notes" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fred-hat-codeready-workspaces-1-1-release-notes%2F&amp;#38;linkname=Red%20Hat%20CodeReady%20Workspaces%201.1%3A%20Release%20notes" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fred-hat-codeready-workspaces-1-1-release-notes%2F&amp;#038;title=Red%20Hat%20CodeReady%20Workspaces%201.1%3A%20Release%20notes" data-a2a-url="https://developers.redhat.com/blog/2019/04/25/red-hat-codeready-workspaces-1-1-release-notes/" data-a2a-title="Red Hat CodeReady Workspaces 1.1: Release notes"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/25/red-hat-codeready-workspaces-1-1-release-notes/"&gt;Red Hat CodeReady Workspaces 1.1: Release notes&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/pTt9CkWTH9g" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;We are pleased to introduce Red Hat CodeReady Workspaces version 1.1, which provides a cloud developer workspace server and browser-based IDE built for teams and organizations. Red Hat CodeReady Workspaces 1.1 includes ready-to-use developer stacks for most of the popular programming languages, frameworks, and Red Hat technologies. This version of Red Hat CodeReady Workspaces introduces: [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/25/red-hat-codeready-workspaces-1-1-release-notes/"&gt;Red Hat CodeReady Workspaces 1.1: Release notes&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2019/04/25/red-hat-codeready-workspaces-1-1-release-notes/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">587017</post-id><dc:creator>Stevan LeMeur</dc:creator><dc:date>2019-04-25T07:05:02Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/25/red-hat-codeready-workspaces-1-1-release-notes/</feedburner:origLink></entry><entry><title>Build and deploy an API with Camel K on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/LBXidytXhAY/" /><category term="Containers" /><category term="Knative" /><category term="Kubernetes" /><category term="OpenShift" /><category term="Serverless" /><category term="Camel K" /><category term="Red Hat OpenShift" /><category term="serverless" /><author><name>Abdellatif BOUCHAMA</name></author><id>https://developers.redhat.com/blog/?p=587377</id><updated>2019-04-25T07:00:20Z</updated><published>2019-04-25T07:00:20Z</published><content type="html">&lt;p&gt;With the growing number of APIs and &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt;, the time given to creating and integrating them has become shorter and shorter. That&amp;#8217;s why we need an integration framework with tooling to quickly build an API and include capabilities for a full API life cycle. Camel K lets you build and deploy your API on &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; or Red Hat OpenShift in less than a second. Unbelievable, isn&amp;#8217;t it?&lt;/p&gt; &lt;p&gt;For those who are not familiar with it, &lt;a href="https://github.com/apache/camel-k"&gt;Camel K&lt;/a&gt; is a subproject of Apache Camel with the target of building a lightweight runtime for running integration code directly on cloud platforms like Kubernetes and &lt;a href="https://developers.redhat.com/blog/2019/03/18/getting-started-with-codeready-workspaces-and-red-hat-openshift-application-runtimes/"&gt;Red Hat OpenShift&lt;/a&gt;. It was inspired by serverless principles, and it will also target Knative shortly. The &lt;a href="https://www.nicolaferraro.me/2018/10/15/introducing-camel-k/"&gt;article by Nicola Ferraro&lt;/a&gt; will give you a good introduction.&lt;/p&gt; &lt;p&gt;In this article, I&amp;#8217;ll show how to build an API with Camel K. For that, we will start first by designing our API using &lt;a href="http://www.apicur.io/"&gt;Apicurio Studio&lt;/a&gt;, which is based on the &lt;a href="https://github.com/OAI/OpenAPI-Specification"&gt;OpenAPI standard&lt;/a&gt;, and then we will provide the OpenAPI standard document to Camel K in order to implement the API and deploy it to Red Hat OpenShift.&lt;span id="more-587377"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Design your API in Apicurio&lt;/h2&gt; &lt;p&gt;Apicurio is a web-based open source tool for designing based on the OpenAPI specification. Go to &lt;a href="https://www.apicur.io/"&gt;https://www.apicur.io/&lt;/a&gt;, then you can start by clicking on &lt;em&gt;Create New API&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;Essentially, you need to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Create the API&lt;/li&gt; &lt;li&gt;Create the data definitions&lt;/li&gt; &lt;li&gt;Add Paths, and define parameters, operations, and return responses to the path&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For each operation (GET, POST), you should configure the &lt;em&gt;Operation ID. &lt;/em&gt;This field is used by Camel K at the build of the REST route in order to redirect this request to a direct endpoint with the same name as the Operation ID. That means your integration routes should start from a direct endpoint (like direct://getCustomer, direct://createCustomer) in order to apply the integration patterns and process those REST requests:&lt;/p&gt; &lt;p&gt;&lt;img class="alignnone" src="https://github.com/abouchama/CamelK-customerAPI/blob/master/images/CamelK_getCustomer.png?raw=true" alt="" width="1197" height="401" /&gt;&lt;/p&gt; &lt;p&gt;Once you have finished the design of your API, download as a JSON file your API based on OpenAPI v2 specification. Here&amp;#8217;s an example of the OpenAPI standard specification of a &lt;a href="https://github.com/abouchama/CamelK-customerAPI/blob/master/customer-api.json"&gt;CustomerAPI.&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;Build your API using Camel K&lt;/h2&gt; &lt;p&gt;To start using Camel K, you need the &lt;code&gt;kamel&lt;/code&gt; binary, which can be used to both configure the cluster and run integrations. Refer to the &lt;a href="https://github.com/apache/camel-k/releases"&gt;release page&lt;/a&gt; for latest version of the &lt;code&gt;kamel&lt;/code&gt; tool.&lt;/p&gt; &lt;div&gt; &lt;p&gt;Once you have the &lt;code&gt;kamel&lt;/code&gt; binary, log into your cluster using the standard &lt;code&gt;oc&lt;/code&gt; (OpenShift) or &lt;code&gt;kubectl&lt;/code&gt; (Kubernetes) client tool and execute the following command to install Camel K:&lt;/p&gt; &lt;pre&gt;kamel install&lt;/pre&gt; &lt;p&gt;At that point, you have just to develop your integration routes in the multiple languages supported by Camel K. In my example, &lt;a href="https://github.com/abouchama/CamelK-customerAPI"&gt;CamelK-customerAPI&lt;/a&gt;, I use plain XML: &lt;a href="https://github.com/abouchama/CamelK-customerAPI/blob/master/customer-api.xml"&gt;customer-api.xml.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You are ready now to build and to deploy your API:&lt;/p&gt; &lt;pre&gt;git clone https://github.com/abouchama/CamelK-customerAPI.git &lt;span class="pl-c1"&gt;cd&lt;/span&gt; CamelK-customerAPI kamel run --dev --name customers --dependency camel-undertow --property camel.rest.port=8080 --open-api customer-api.json customer-api.xml&lt;/pre&gt; &lt;p&gt;You can check the status of your integration by running the following command:&lt;/p&gt; &lt;pre&gt;oc get it NAME      PHASE   CONTEXT customers Running  ctx-biq59ca78n55k4851cjg&lt;/pre&gt; &lt;p&gt;Logs show:&lt;/p&gt; &lt;p&gt;&lt;img class="alignnone size-medium" src="https://github.com/abouchama/CamelK-customerAPI/blob/master/images/CamelK_Routes_Started.png?raw=true" width="1906" height="531" /&gt;&lt;/p&gt; &lt;p&gt;Congratulations! Your first API was built and deployed on Red Hat OpenShift in less than one second, as you can see from the last line of the log.&lt;/p&gt; &lt;h2&gt;Tips&lt;/h2&gt; &lt;p&gt;By setting the logging level to DEBUG, you can see the print of the rests routes converted from the provided OpenAPI specification in the parameter &lt;code&gt;--open-api&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;kamel run --dev --name customers --dependency camel-undertow --property camel.rest.port=8080 --open-api customer-api.json --logging-level org.apache.camel.k=DEBUG customer-api.xml&lt;/pre&gt; &lt;p&gt;&lt;img class="alignnone " src="https://github.com/abouchama/CamelK-customerAPI/blob/master/images/CamelK-Rests.png?raw=true" width="1173" height="315" /&gt;&lt;/p&gt; &lt;p&gt;To monitor your Camel K routes with Hawtio, simply enable the &lt;em&gt;jolokia&lt;/em&gt; trait (&lt;code&gt;-t jolokia.enabled=true&lt;/code&gt;), and the button &lt;em&gt;Open Java Console&lt;/em&gt; will appear. For monitoring with Prometheus, you can simply enable the &lt;em&gt;prometheus&lt;/em&gt; trait (&lt;code&gt;-t prometheus.enabled=true&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;kamel run --dev --name customers --dependency camel-undertow --property camel.rest.port=8080 -t jolokia.enabled=true -t prometheus.enabled=true -t prometheus.service-monitor=false --open-api customer-api.json --logging-level org.apache.camel.k=DEBUG customer-api.xml&lt;/pre&gt; &lt;p&gt;Thanks for reading, and I hope that you enjoyed this article.&lt;/p&gt; &lt;p&gt;The video below walks through what I&amp;#8217;ve covered in this article:&lt;/p&gt; &lt;/div&gt; &lt;p&gt;&lt;iframe src="https://www.youtube.com/embed/WE8K6872w1U" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fbuild-and-deploy-an-api-with-camel-k-on-red-hat-openshift%2F&amp;#38;linkname=Build%20and%20deploy%20an%20API%20with%20Camel%20K%20on%20Red%20Hat%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fbuild-and-deploy-an-api-with-camel-k-on-red-hat-openshift%2F&amp;#38;linkname=Build%20and%20deploy%20an%20API%20with%20Camel%20K%20on%20Red%20Hat%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fbuild-and-deploy-an-api-with-camel-k-on-red-hat-openshift%2F&amp;#38;linkname=Build%20and%20deploy%20an%20API%20with%20Camel%20K%20on%20Red%20Hat%20OpenShift" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fbuild-and-deploy-an-api-with-camel-k-on-red-hat-openshift%2F&amp;#38;linkname=Build%20and%20deploy%20an%20API%20with%20Camel%20K%20on%20Red%20Hat%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fbuild-and-deploy-an-api-with-camel-k-on-red-hat-openshift%2F&amp;#38;linkname=Build%20and%20deploy%20an%20API%20with%20Camel%20K%20on%20Red%20Hat%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fbuild-and-deploy-an-api-with-camel-k-on-red-hat-openshift%2F&amp;#38;linkname=Build%20and%20deploy%20an%20API%20with%20Camel%20K%20on%20Red%20Hat%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fbuild-and-deploy-an-api-with-camel-k-on-red-hat-openshift%2F&amp;#38;linkname=Build%20and%20deploy%20an%20API%20with%20Camel%20K%20on%20Red%20Hat%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fbuild-and-deploy-an-api-with-camel-k-on-red-hat-openshift%2F&amp;#38;linkname=Build%20and%20deploy%20an%20API%20with%20Camel%20K%20on%20Red%20Hat%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F25%2Fbuild-and-deploy-an-api-with-camel-k-on-red-hat-openshift%2F&amp;#038;title=Build%20and%20deploy%20an%20API%20with%20Camel%20K%20on%20Red%20Hat%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2019/04/25/build-and-deploy-an-api-with-camel-k-on-red-hat-openshift/" data-a2a-title="Build and deploy an API with Camel K on Red Hat OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/25/build-and-deploy-an-api-with-camel-k-on-red-hat-openshift/"&gt;Build and deploy an API with Camel K on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/LBXidytXhAY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;With the growing number of APIs and microservices, the time given to creating and integrating them has become shorter and shorter. That&amp;#8217;s why we need an integration framework with tooling to quickly build an API and include capabilities for a full API life cycle. Camel K lets you build and deploy your API on Kubernetes [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/25/build-and-deploy-an-api-with-camel-k-on-red-hat-openshift/"&gt;Build and deploy an API with Camel K on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2019/04/25/build-and-deploy-an-api-with-camel-k-on-red-hat-openshift/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">587377</post-id><dc:creator>Abdellatif BOUCHAMA</dc:creator><dc:date>2019-04-25T07:00:20Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/25/build-and-deploy-an-api-with-camel-k-on-red-hat-openshift/</feedburner:origLink></entry><entry><title>bpmNEXT 2019 impressions, day 3</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/RoZjc5DxAbA/bpmnext-2019-impressions-day-3.html" /><category term="bpmNEXT" scheme="searchisko:content:tags" /><category term="Demo" scheme="searchisko:content:tags" /><category term="feed_group_name_jbpm" scheme="searchisko:content:tags" /><category term="feed_name_kverlaen" scheme="searchisko:content:tags" /><category term="Presentation" scheme="searchisko:content:tags" /><author><name>Kris Verlaenen</name></author><id>searchisko:content:id:jbossorg_blog-bpmnext_2019_impressions_day_3</id><updated>2019-04-24T10:52:55Z</updated><published>2019-04-24T10:52:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div style="text-align: justify;"&gt;Last (half) day where I have to present myself as well (as 3rd of the day)&lt;b&gt;.&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;A Well-Mixed Cocktail: Blending Decision and RPA Technologies in 1st Gen Design Patterns&lt;/b&gt;&lt;br /&gt;&lt;i&gt;Lloyd Dugan&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;Lloyd introduced an RPA-enabled case mgmt platform that is used in the context of a use case to determine eligibility for Affordable Care Act. Using Sapiens for decisions and Appian for BPM, approximately 4000 people are using this as a work mgmt application (where work is assigned to people so they can work through this).&amp;nbsp; To be able to achieve higher throughput, they however combined this with RPA that emulate the behavoir of the users.&amp;nbsp; He showed (unfortunately in a prerecorded video, not a live demo) how they implemented the robots to perform some of the work (up to 50% of the total work done by the users !). The robots learned how to soft fail if there were issues (in which case the work would go back into the queue), needed to accomodate for latency, etc. &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Emergent Synthetic Process&lt;/b&gt;&lt;br /&gt;&lt;i&gt;Keith Swenson - Fujitsu&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;Keith presented a way to customize processes to different contexts (for example slightly different regulations / approaches in different countries) by being able to generate a customized process for your specific context (when you start the process).&amp;nbsp; Rather than encoding processes in a procedural manner (after A do B), he is using "service descriptions" to define the tasks and the preconditions. You can then generate a process from this by specifying your goal and context and working backwards to create a customized process from this.&amp;nbsp; This allows you to add new tasks to these processes easily (as this is much more declarative logic and therefore additive).&lt;br /&gt;The demo showed a travel application with approval by different people. Service descriptions can have required tasks, required data, etc.&amp;nbsp; The process is generated by working backwards from the goal, adding required steps one by one.&amp;nbsp; Different countries can add their own steps, leading to small customizations in the generated process. &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Automating Human-Centric Processes with Machine Learning&lt;/b&gt;&lt;br /&gt;&lt;i&gt;Kris Verlaenen - Red Hat&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;I was up next !&amp;nbsp; I presented on how to combine Process Automation and Machine Learning (ML), to create a platform that combines the benefits of encoding business logic using a combination of business processes, rules etc. but at the same time can become more intelligent over time by observing and learning from the data during execution.&amp;nbsp; The focus was on introducing "non-intrusive" ways of combining processes with ML, to assist users with performing their tasks rather than to try and replace them.&lt;br /&gt;The demo was using the it-orders application (one of our out-of-the-box case management demos that employees can use to order laptops) that focused on 3 main use cases:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;Augmenting task data&lt;/i&gt;:&amp;nbsp; While human actors are performing tasks in your processes or cases, we can observe the data and try to predict task outcomes based on task inputs.&amp;nbsp; Once the ML algorithm (using Random Forest algorithm, with the SMILE library as the implementation) has been trained a little, it can start augmenting the data with possible predictions, but also with a confidence it has on that prediction, the relative importance of the input parameters, etc.&amp;nbsp; In this case, the manager approving the order would be able to see this augmented data in his task form and use it to make the right decision.&lt;/li&gt;&lt;li&gt;&lt;i&gt;Recommending tasks&lt;/i&gt;:&amp;nbsp; Case management allows users to add addition dynamic tasks to running cases (even though they weren't modeled in the case upfront) in specific situations.&amp;nbsp; Similarly, these can be monitored and ML could be used to detect patterns.&amp;nbsp; These could be turned into recommendations, where a user is presented with a recommendation to do (or assign) a task based on what the ML algorithm has learned.&amp;nbsp; This can help the users significantly to not forget things or to assist them by preparing most of the work (they simply have to accept the recommendation).&lt;/li&gt;&lt;li&gt;&lt;i&gt;Optimizing processes based on ML&lt;/i&gt;: One of the advantages of the Random Forest algorithm is that you can inspect the decision trees that are being trained to see what they have learned so far.&amp;nbsp; Since ML also has disadvantages (that it can be biased or that it is simply learning from what is being done, which is not necessarily correct behavior), analyzing what was learned so far and integrating this back into the process (and/or rules etc.) has significant advantages as well.&amp;nbsp;&amp;nbsp; We extended the existing case with additional logic (like for example an additional decision service to determine whether some manager approvals could be automated, or additional ad-hoc tasks included in the case that would be triggered under certain circumstances), so that some of the patterns detected by ML would be encoded and enforced by the case logic itself.&lt;/li&gt;&lt;/ul&gt;These non-introsive ways of combining processes with ML is very complementary (as it allows us to take advantage of both approaches which mitigates some of the disadvantages of ML) and allows users to start getting advantages of ML and build up confidence in small and incremental steps.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;b&gt;ML, Conversational UX, and Intelligence in BPM&lt;/b&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;i&gt;Andre Hofeditz, Seshadri Sreeniva - SAP SE&lt;/i&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;SAP is presenting "live processes" that are created by combining predefined building blocks, running on their platform with support for conversational user experience, decision management, task inbox, etc.&amp;nbsp;&amp;nbsp;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;SAP API Business Hub has been extended to also include live processes. Using an employee onboarding scenario, they show how a running instance can be "configured" (only in specific situations, which you can define during authoring) after which you can change the template and generate a new variant.&amp;nbsp; The process visibility workbench allows to generate a customizable UI for monitoring progress of your processes.&lt;/div&gt;&lt;div style="text-align: justify;"&gt;Next, they show how you can extend the platform by using recipes, which can be imported in SAP web IDE and deployed into the platform, adding additional capabilities that will be available in your live processes from that point forward.&lt;/div&gt;&lt;div style="text-align: justify;"&gt;Finally, they showed an intelligent assistant that is a sort of chatbot that can respond to voice.&amp;nbsp; It can give an aggregated view of your tasks, complete the tasks through the conversational UI, etc.&amp;nbsp; They showed how the chatbot can be programmed by defining tasks with triggers, requirements and actions, which can then be deployed as a microservice on the SAP cloud.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;DMN TCK&lt;/b&gt;&lt;br /&gt;&lt;i&gt;Keith Swenson&amp;nbsp;&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;Keith&lt;i&gt; &lt;/i&gt;explained the efforts that are going into the DMN TCK, a set of tests to verify the compliance of DMN engines.&amp;nbsp; When running these tests, it takes a large number of models and test cases (currently over a thousand but still growing) and check the results.&amp;nbsp; He explained some of the challenges and opportunities in this context (e.g. error handling).&lt;br /&gt;While many vendors claim DMN compatibility, Red Hat is one of the few vendors that actually has the results to prove it !&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;That concludes bpmNEXT 2019!&amp;nbsp; As previous years, I very much enjoyed the presentations, but probably even more the discussions during the breakouts and evenings.&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/RoZjc5DxAbA" height="1" width="1" alt=""/&gt;</content><summary>Last (half) day where I have to present myself as well (as 3rd of the day). A Well-Mixed Cocktail: Blending Decision and RPA Technologies in 1st Gen Design Patterns Lloyd Dugan Lloyd introduced an RPA-enabled case mgmt platform that is used in the context of a use case to determine eligibility for Affordable Care Act. Using Sapiens for decisions and Appian for BPM, approximately 4000 people are us...</summary><dc:creator>Kris Verlaenen</dc:creator><dc:date>2019-04-24T10:52:00Z</dc:date><feedburner:origLink>http://kverlaen.blogspot.com/2019/04/bpmnext-2019-impressions-day-3.html</feedburner:origLink></entry><entry><title>How to run systemd in a container</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/5QRBMS2wE74/" /><category term="Containers" /><category term="containers" /><category term="Podman" /><category term="systemd" /><author><name>Daniel Walsh</name></author><id>https://developers.redhat.com/blog/?p=589467</id><updated>2019-04-24T07:02:10Z</updated><published>2019-04-24T07:02:10Z</published><content type="html">&lt;p&gt;I have been talking about &lt;a href="https://github.com/systemd/systemd"&gt;systemd&lt;/a&gt; in a container for a long time. Way back in 2014, I wrote “&lt;a href="https://developers.redhat.com/blog/2014/05/05/running-systemd-within-docker-container/"&gt;Running systemd within a Docker Container&lt;/a&gt;.” And, a couple of years later, I wrote another article, “&lt;a href="https://developers.redhat.com/blog/2016/09/13/running-systemd-in-a-non-privileged-container/"&gt;Running systemd in a non-privileged container&lt;/a&gt;,” explaining how things hadn’t gotten much better. In that article, I stated, “Sadly, two years later if you google Docker systemd, this is still the article people see—it’s time for an update.” I also linked to a talk about &lt;a href="https://lwn.net/Articles/676831/"&gt;how upstream Docker and upstream systemd would not compromise.&lt;/a&gt; In this article, I&amp;#8217;ll look at the progress that&amp;#8217;s been made and how Podman can help. &lt;span id="more-589467"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;There are lots of reasons to run systemd inside a system, such as:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;b&gt;Multiservice containers&lt;/b&gt;—Lots of people want to take existing multi-service applications out of VMs and run them inside of containers. We would prefer that they break apart these applications into microservices, but some people can’t or don’t have time yet.  So running them as services launched out of unit files by systemd makes sense.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Systemd unit files&lt;/b&gt;—Most applications that run inside of containers are built from code that was run in VMs or on host systems. These applications have a unit file that was written for the application and understands how to run the application. It can be better to launch the service via the supported method, rather than to hack up your own init service.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Systemd is a process manager&lt;/b&gt;—It handles the management of services like reaping, restarting, and shutting down better than any other tool.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;That being said, there are also lots of reasons not to run systemd in containers. The main one is that systemd/journald controls the output of containers, whereas tools like &lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt; and &lt;a href="https://www.openshift.com/"&gt;OpenShift&lt;/a&gt; expect the containers to log directly to stdout and stderr. So, if you are going to manage your containers via Orchestrator like these, then you should think twice about using systemd-based containers. Additionally, the upstream community of Docker and Moby were often hostile to the use of systemd in a container.&lt;/p&gt; &lt;h2&gt;Enter Podman&lt;/h2&gt; &lt;p&gt;I am happy to say things have gotten better. My team, container runtimes, at Red Hat decided to build &lt;a href="https://podman.io/"&gt;our own container engine&lt;/a&gt;, called &lt;a href="https://github.com/containers/libpod"&gt;Podman&lt;/a&gt;. Podman is a container engine with the same command-line interface (CLI) as Docker. Pretty much every command you can run from the Docker command line you can execute with &lt;a href="https://developers.redhat.com/blog/tag/podman/"&gt;Podman&lt;/a&gt;. I often give a talk now called &lt;a href="https://podman.io/talks/2018/10/01/talk-replace-docker-with-podman.html"&gt;Replacing Docker with Podman&lt;/a&gt;, where the first slide says &lt;code&gt;alias docker=podman&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;And lots of people had.&lt;/p&gt; &lt;p&gt;With Podman, however, we were not hostile to systemd-based containers. Systemd is the most prevalent Linux init system on the planet, and not allowing it to run properly within a container would ignore the way thousands of users choose to run containers.&lt;/p&gt; &lt;p&gt;Podman understands what systemd needs to do to run in a container. It requires things like tmpfs mounted at /run and /tmp. It likes to have the “container” environment turned on, and it expects to be able to write to its portion of the cgroup directory and to the /var/log/journald directory.&lt;/p&gt; &lt;p&gt;When Podman starts a container that is running init or systemd as its initial command, Podman automatically sets up the tmpfs and Cgroups for systemd to start without a problem. If you want to block the systemd behavior, you have to run &lt;code&gt;--systemd=false&lt;/code&gt;. Note that the systemd behavior only happens when Podman sees the command to be executed is systemd or init.&lt;/p&gt; &lt;p&gt;Here is the man page description:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;man podman run&lt;/p&gt; &lt;p&gt;…&lt;/p&gt; &lt;p&gt;&amp;#8211;systemd=true|false&lt;/p&gt; &lt;p&gt;Run container in systemd mode. The default is true.&lt;/p&gt; &lt;p&gt;If the command you running inside of the container is systemd or init, podman will setup tmpfs mount points in the following directories:&lt;/p&gt; &lt;p&gt;/run, /run/lock, /tmp, /sys/fs/cgroup/systemd, /var/lib/journal&lt;/p&gt; &lt;p&gt;It will also set the default stop signal to SIGRTMIN+3.&lt;/p&gt; &lt;p&gt;This allows systemd to run in a confined container without any modifications.&lt;/p&gt; &lt;p&gt;Note: On SELinux systems, systemd attempts to write to the cgroup file system.  Containers writing to the cgroup file system are denied by default. The container_manage_cgroup boolean must be enabled for this to be allowed on an SELinux separated system.&lt;/p&gt; &lt;p&gt;setsebool -P container_manage_cgroup true&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Now let’s look at a Dockerfile for running systemd in a container using Podman:&lt;/p&gt; &lt;pre&gt;# cat Dockerfile FROM fedora RUN dnf -y install httpd; dnf clean all; systemctl enable httpd EXPOSE 80 CMD [ "/sbin/init" ] &lt;/pre&gt; &lt;p&gt;That’s it.&lt;/p&gt; &lt;p&gt;Build the container&lt;/p&gt; &lt;pre&gt;# podman build -t systemd .&lt;/pre&gt; &lt;p&gt;Tell SELinux it is ok to allow systemd to manipulate its Cgroups configuration.&lt;/p&gt; &lt;pre&gt;# setsebool -P container_manage_cgroup true&lt;/pre&gt; &lt;p&gt;You will forget to do this; I did while writing this blog. Luckily, you do this once, and it will be set for the lifetime of the system.&lt;/p&gt; &lt;p&gt;Now just run the container.&lt;/p&gt; &lt;pre&gt;# podman run -ti -p 80:80 systemd systemd 239 running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 +SECCOMP +BLKID +ELFUTILS +KMOD +IDN2 -IDN +PCRE2 default-hierarchy=hybrid) Detected virtualization container-other. Detected architecture x86-64. Welcome to Fedora 29 (Container Image)! Set hostname to &amp;#60;1b51b684bc99&amp;#62;. Failed to install release agent, ignoring: Read-only file system File /usr/lib/systemd/system/systemd-journald.service:26 configures an IP firewall (IPAddressDeny=any), but the local system does not support BPF/cgroup based firewalling. Proceeding WITHOUT firewalling in effect! (This warning is only shown for the first loaded unit using IP firewalling.) [  OK ] Listening on initctl Compatibility Named Pipe. [  OK ] Listening on Journal Socket (/dev/log). [  OK ] Started Forward Password Requests to Wall Directory Watch. [  OK ] Started Dispatch Password Requests to Console Directory Watch. [  OK ] Reached target Slices. … [  OK ] Started The Apache HTTP Server. &lt;/pre&gt; &lt;p&gt;And the service is up and running.&lt;/p&gt; &lt;pre&gt;$ curl localhost &amp;#60;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"&amp;#62; … &amp;#60;/html&amp;#62; &lt;/pre&gt; &lt;p&gt;Note: Don’t try this with Docker you still need to jump through hoops to get a container like this running in the daemon. (You need additional fields and packages, to make this work seamlessly in Docker, or run in a &amp;#8211;privileged container. &lt;a href="https://developers.redhat.com/blog/2016/09/13/running-systemd-in-a-non-privileged-container/"&gt;My previous article&lt;/a&gt; explains this better.)&lt;/p&gt; &lt;h2&gt;Other cool features about Podman and systemd&lt;/h2&gt; &lt;h3&gt;Podman in systemd unit files works better than Docker&lt;/h3&gt; &lt;p&gt;When launching containers at boot, you can simply put Podman commands into a systemd unit file, and systemd will launch and monitor the service. Podman is a standard fork and exec model. That means the container processes are children of the Podman process, so systemd has an easy time monitoring the processes.&lt;/p&gt; &lt;p&gt;Docker is a client service model and putting the Docker CLI into a unit file is possible. However, as the Docker client connects to the Docker daemon, the Docker client becomes just another process handling stdin and stdout. Systemd has no idea of this relationship between the Docker client and the container that is running under the Docker daemon and can&amp;#8217;t monitor the service in this model.&lt;/p&gt; &lt;h3&gt;Systemd socket activation&lt;/h3&gt; &lt;p&gt;Podman works correctly when the socket is activated. Because Podman is a fork/exec model, it can pass the connected socket down to its children container processes. Docker cannot do this because of the client/server model.&lt;/p&gt; &lt;p&gt;Podman &lt;a href="https://varlink.org/"&gt;varlink&lt;/a&gt;, a service that Podman uses for remote clients to interact with containers, is actually socket activated. The &lt;a href="https://github.com/cockpit-project/cockpit-podman"&gt;cockpit-podman&lt;/a&gt; package, written in Node.js, is part of the cockpit project and allows people to interact with Podman containers via a web interface. The web daemon running cockpit-podman sends messages to a varlink socket that systemd is listening on. Systemd then activates the Podman program to receive the messages and start managing containers. Systemd socket activation allows us to have no long-running daemon and still be able to handle a remote API.&lt;/p&gt; &lt;p&gt;We are developing another client for Podman, called&lt;em&gt; podman-remote&lt;/em&gt;, which implements the same Podman CLI but calls into varlink to launch containers. Podman-remote can work over SSH sessions, allowing us to securely interact with containers on different machines. We eventually plan on using podman-remote to support MacOS and Windows users as well as Linux users. This will allow developers on a Mac or Windows box to launch a Linux VM with Podman varlink running and have the feeling that containers are running on their local machine.&lt;/p&gt; &lt;h3&gt;SD_NOTIFY&lt;/h3&gt; &lt;p&gt;Systemd has the ability to hold up secondary services from starting that rely on a containerized service starting. Podman can pass down the SD_NOTIFY Socket to the containerized service, so it can notify systemd when it is ready to begin servicing requests. Docker again cannot do this, because of the client/server model.&lt;/p&gt; &lt;h2&gt;Future Work&lt;/h2&gt; &lt;p&gt;We have plans to add a &lt;code&gt;podman generate systemd CONTAINERID&lt;/code&gt;, which would generate a systemd unit file for managing the specified container. This should work in either root or rootless mode for non-privileged containers. I have even seen a PR to create a systemd-nspawn OCI-compliant runtime.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Running systemd in a container is a reasonable thing to do. Finally, we have a container runtime in Podman that is not hostile to running systemd fully but easily enables the workload.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fhow-to-run-systemd-in-a-container%2F&amp;#38;linkname=How%20to%20run%20systemd%20in%20a%20container" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fhow-to-run-systemd-in-a-container%2F&amp;#38;linkname=How%20to%20run%20systemd%20in%20a%20container" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fhow-to-run-systemd-in-a-container%2F&amp;#38;linkname=How%20to%20run%20systemd%20in%20a%20container" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fhow-to-run-systemd-in-a-container%2F&amp;#38;linkname=How%20to%20run%20systemd%20in%20a%20container" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fhow-to-run-systemd-in-a-container%2F&amp;#38;linkname=How%20to%20run%20systemd%20in%20a%20container" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fhow-to-run-systemd-in-a-container%2F&amp;#38;linkname=How%20to%20run%20systemd%20in%20a%20container" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fhow-to-run-systemd-in-a-container%2F&amp;#38;linkname=How%20to%20run%20systemd%20in%20a%20container" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fhow-to-run-systemd-in-a-container%2F&amp;#38;linkname=How%20to%20run%20systemd%20in%20a%20container" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fhow-to-run-systemd-in-a-container%2F&amp;#038;title=How%20to%20run%20systemd%20in%20a%20container" data-a2a-url="https://developers.redhat.com/blog/2019/04/24/how-to-run-systemd-in-a-container/" data-a2a-title="How to run systemd in a container"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/24/how-to-run-systemd-in-a-container/"&gt;How to run systemd in a container&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/5QRBMS2wE74" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;I have been talking about systemd in a container for a long time. Way back in 2014, I wrote “Running systemd within a Docker Container.” And, a couple of years later, I wrote another article, “Running systemd in a non-privileged container,” explaining how things hadn’t gotten much better. In that article, I stated, “Sadly, two [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/24/how-to-run-systemd-in-a-container/"&gt;How to run systemd in a container&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2019/04/24/how-to-run-systemd-in-a-container/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">589467</post-id><dc:creator>Daniel Walsh</dc:creator><dc:date>2019-04-24T07:02:10Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/24/how-to-run-systemd-in-a-container/</feedburner:origLink></entry><entry><title>Using Quiver with AMQ on Red Hat OpenShift Container Platform</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/l7ZAenG0X2k/" /><category term="JBoss A-MQ" /><category term="Performance" /><category term="Red Hat OpenShift Container Platform" /><category term="OpenShift Container Platform" /><category term="Quiver" /><category term="Red Hat AMQ" /><author><name>gahealy</name></author><id>https://developers.redhat.com/blog/?p=588787</id><updated>2019-04-24T07:00:57Z</updated><published>2019-04-24T07:00:57Z</published><content type="html">&lt;p&gt;As part of the Red Hat &lt;a href="https://www.redhat.com/en/services/consulting"&gt;UKI Professional Services&lt;/a&gt; team, I have worked with several customers who are implementing &lt;a href="https://developers.redhat.com/products/amq/overview/"&gt;AMQ Broker&lt;/a&gt; on &lt;a href="https://developers.redhat.com/products/openshift/overview/"&gt;Red Hat OpenShift Container Platform (OCP)&lt;/a&gt;. One question customers typically ask is, “How do we validate that the AMQ configuration is correct for our scenario?” Previously, I would have suggested one of the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="http://activemq.apache.org/activemq-performance-module-users-manual.html"&gt;ActiveMQ Perf Maven plugin&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://activemq.apache.org/jmeter-performance-tests.html"&gt;JMeter&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://gatling.io/docs/3.0/jms/"&gt;Gatling&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These tools can give you indicators around:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Is the broker up and running? That is, can it receive/publish messages for this configuration?&lt;/li&gt; &lt;li&gt;Can the broker handle a certain performance characteristic? That is, what is my minimum publish rate per second for this configuration?&lt;/li&gt; &lt;li&gt;And much more.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The problem with these tools is that you cannot choose the client technology. This could lead to real-world differences and limited technology choices, which in turn might lead you down the wrong technology path. In other words:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Do you get the same performance from JMeter versus the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.2/html/amq_clients_overview/components"&gt;AMQ clients&lt;/a&gt; you would use in production? Are you comparing like for like? Apples with apples?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;So, what do I think is the answer? &lt;a href="https://github.com/ssorj/quiver"&gt;Quiver &lt;/a&gt;&lt;a href="#DISCLAIMER"&gt;[1]&lt;/a&gt;. In this article, I&amp;#8217;ll provide an overview and demo of using Quiver with Red Hat AMQ on Red Hat OpenShift.  If you&amp;#8217;re looking for more information on Red Hat AMQ and how it can help, check out this &lt;a href="https://youtu.be/mkqVxWZfGfI"&gt;webinar.&lt;/a&gt;&lt;span id="more-588787"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2 id="what-is-quiver"&gt;What is Quiver?&lt;/h2&gt; &lt;p&gt;Straight from the &lt;a href="https://github.com/ssorj/quiver"&gt;Quiver GitHub page&lt;/a&gt;:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;Quiver implementations are native clients (and sometimes also servers) in various languages and APIs that either send or receive messages and write raw information about the transfers to standard output. They are deliberately simple.&lt;/p&gt;&lt;/blockquote&gt; &lt;blockquote&gt;&lt;p&gt;The quiver-arrow command runs a single implementation in send or receive mode and captures its output. It has options for defining the execution parameters, selecting the implementation, and reporting statistics.&lt;/p&gt;&lt;/blockquote&gt; &lt;blockquote&gt;&lt;p&gt;The quiver command launches a pair of quiver-arrow instances, one sender and one receiver, and produces a summary of the end-to-end transmission of messages.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;In my own words;&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;Quiver is a tool that starts both a publisher and receiver client with the aim of completing as fast as possible. Once the publisher and receiver have completed; a statistical output is generated which can give you insight into how the test has performed.&lt;/p&gt;&lt;/blockquote&gt; &lt;blockquote&gt;&lt;p&gt;The clients are based on the &lt;a href="https://qpid.apache.org/"&gt;Apache Qpid&lt;/a&gt; project that offers; Java, C++, Python and Javascript implementations to name a few. The clients primarily target &lt;a href="https://download.oracle.com/otndocs/jcp/jms-2_0-fr-eval-spec/"&gt;JMS&lt;/a&gt; and &lt;a href="http://www.amqp.org/resources/download"&gt;AMQP&lt;/a&gt; users.&lt;/p&gt;&lt;/blockquote&gt; &lt;h2 id="recorded-demo"&gt;Recorded demo&lt;/h2&gt; &lt;p&gt;Feeling lazy and want to watch an &lt;a href="https://asciinema.org/"&gt;asciinema&lt;/a&gt; recording?&lt;/p&gt; &lt;p&gt;The demo will show the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;AMQ Broker and AMQ Interconnect being deployed onto OKD running on Minishift&lt;/li&gt; &lt;li&gt;Send and receive messages via Quiver using the Core protocol to the broker&lt;/li&gt; &lt;li&gt;Send and receive messages via Quiver using a JMS client over AMQP protocol to the broker&lt;/li&gt; &lt;li&gt;Send and receive messages via Quiver using a JMS client over AMQP protocol to interconnect&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a href="https://asciinema.org/a/240989"&gt;&lt;img src="https://asciinema.org/a/240989.png" alt="asciicast" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2 id="do-it-yourself-demo"&gt;Do it yourself demo&lt;/h2&gt; &lt;p&gt;Want to play with Quiver, AMQ, and OCP yourself?&lt;/p&gt; &lt;p&gt;The demo uses an OCP template which requires two arguments:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;DOCKER_IMAGE; location of the fully qualified docker pull URL. This can be resolved via the imported image stream; &lt;code&gt;oc get is quiver -o jsonpath=‘{.status.dockerImageRepository}’&lt;/code&gt;&lt;/li&gt; &lt;li&gt;DOCKER_CMD; the quiver command, in JSON array format, you want to execute.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id="demo-prerequisites"&gt;Demo prerequisites&lt;/h3&gt; &lt;p&gt;It is presumed that you have the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Basic knowledge of the OCP CLI and web console&lt;/li&gt; &lt;li&gt;A running &lt;a href="https://developers.redhat.com/products/openshift/overview/"&gt;Red Hat OpenShift Container Platform (OCP)&lt;/a&gt; or &lt;a href="https://github.com/minishift/minishift"&gt;Minishift&lt;/a&gt; environment&lt;/li&gt; &lt;li&gt;AMQ Broker templates and image streams installed by following this documentation: &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.2/html-single/deploying_amq_broker_on_openshift_container_platform/index#install-deploy-ocp-broker-ocp"&gt;2.1. Installing AMQ Broker on OpenShift Container Platform image streams and application templates&lt;/a&gt;&lt;/li&gt; &lt;li&gt;AMQ Interconnect templates and image streams installed by following: &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.2/html/deploying_amq_interconnect_on_openshift_container_platform/preparing-to-deploy-router-ocp"&gt;2.1. Verifying the availability of AMQ Interconnect templates&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3 id="setup"&gt;Setup&lt;/h3&gt; &lt;ol type="1"&gt; &lt;li&gt;Create project &lt;pre&gt; $ oc new-project quiver&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Import the Quiver image &lt;pre&gt; $ oc import-image quiver:latest --from=docker.io/ssorj/quiver --confirm&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Add the view role to the default service account &lt;pre&gt; $ oc policy add-role-to-user view system:serviceaccount:$(oc project -q):default&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Deploy AMQ Broker &lt;pre&gt; $ oc new-app --template=amq-broker-72-basic \ -e AMQ_PROTOCOL=openwire,amqp,stomp,mqtt \ -e AMQ_QUEUES=quiver \ -e AMQ_ADDRESSES=quiver \ -e AMQ_USER=anonymous \ -e ADMIN_PASSWORD=password $ oc get pods --watch&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Deploy AMQ Interconnect &lt;pre&gt; $ oc new-app --template=amq-interconnect-1-basic $ oc get pods --watch&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h3 id="send-messages-to-amq-broker"&gt;Send messages to AMQ Broker&lt;/h3&gt; &lt;ol start="6" type="1"&gt; &lt;li&gt;Send 1,000,000 messages to the broker via the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.2/html-single/using_the_amq_core_protocol_jms_client/"&gt;core protocol&lt;/a&gt; &lt;pre&gt; $ oc process -f https://raw.githubusercontent.com/ssorj/quiver/0.2.0/packaging/openshift/openshift-pod-template.yml \ DOCKER_IMAGE=$(oc get is quiver -o jsonpath='{.status.dockerImageRepository}'):latest \ DOCKER_CMD="[\"quiver\", \"//broker-amq-tcp:61616/activemq-artemis-jms\", \"--impl\", \"activemq-artemis-jms\", \"--verbose\"]" \ | oc create -f -&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Look at output for core protocol pod &lt;pre&gt; $ oc get pods --watch $ oc logs -f {insert value of new pod name} ---------------------- Sender ----------------------- --------------------- Receiver ---------------------- -------- Time [s] Count [m] Rate [m/s] CPU [%] RSS [M] Time [s] Count [m] Rate [m/s] CPU [%] RSS [M] Lat [ms] ----------------------------------------------------- ----------------------------------------------------- -------- 2.3 0 0 73 64.6 2.3 0 0 73 63.8 0 4.3 3,337 1,667 71 100.0 4.3 2,529 1,261 75 96.6 42 6.3 24,727 10,684 71 116.0 6.4 25,178 11,223 106 123.1 36 8.3 113,170 44,177 64 116.7 8.4 116,495 45,658 66 123.9 2 10.3 221,942 54,359 59 116.8 10.4 227,809 55,491 50 124.0 2 12.3 327,983 52,994 56 116.8 12.4 332,016 52,077 44 122.3 2 14.3 428,866 50,391 54 116.8 14.4 433,091 50,512 41 122.5 2 16.3 540,823 55,923 62 117.1 16.4 547,056 56,926 49 122.6 2 18.3 645,499 52,312 60 117.1 18.4 648,975 50,934 48 122.6 2 20.3 761,704 58,073 58 117.1 20.4 768,000 59,453 55 122.7 2 22.3 873,509 55,875 61 117.2 22.4 874,857 53,348 50 122.7 3 24.3 914,014 20,242 33 117.2 24.5 923,768 22,728 27 122.7 4 26.3 1,000,000 42,950 53 117.4 26.5 1,000,000 38,078 45 0.0 2 -------------------------------------------------------------------------------- Subject: activemq-artemis-jms //broker-amq-tcp:61616/activemq-artemis-jms (/tmp/quiver-xo6l0q4a) Count: 1,000,000 messages Body size: 100 bytes Credit window: 1,000 messages Duration: 23.0 s Sender rate: 43,414 messages/s Receiver rate: 43,507 messages/s End-to-end rate: 43,407 messages/s Latencies by percentile: 0%: 0 ms 90.00%: 4 ms 25%: 2 ms 99.00%: 20 ms 50%: 2 ms 99.90%: 249 ms 100%: 307 ms 99.99%: 290 ms --------------------------------------------------------------------------------&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Send 1,000,000 messages to the broker via the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.2/html-single/using_the_amq_jms_client/"&gt;JMS client over AMQP protocol&lt;/a&gt; &lt;pre&gt; $ oc process -f https://raw.githubusercontent.com/ssorj/quiver/0.2.0/packaging/openshift/openshift-pod-template.yml \ DOCKER_IMAGE=$(oc get is quiver -o jsonpath='{.status.dockerImageRepository}'):latest \ DOCKER_CMD="[\"quiver\", \"amqp://broker-amq-amqp:5672/qpid-jms-over-ampq\", \"--impl\", \"qpid-jms\", \"--verbose\"]" \ | oc create -f -&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Look at output for the AMQP client pod &lt;pre&gt; $ oc get pods --watch $ oc logs -f {insert value of new pod name} ---------------------- Sender ----------------------- --------------------- Receiver ---------------------- -------- Time [s] Count [m] Rate [m/s] CPU [%] RSS [M] Time [s] Count [m] Rate [m/s] CPU [%] RSS [M] Lat [ms] ----------------------------------------------------- ----------------------------------------------------- -------- 2.2 2,663 1,330 109 103.1 2.2 1,984 991 94 94.6 89 4.2 16,304 6,817 118 110.7 4.2 16,113 7,050 115 113.2 56 6.2 45,720 14,693 102 119.7 6.2 45,809 14,767 97 115.4 118 8.2 105,097 29,674 88 120.8 8.2 92,810 23,489 84 115.6 305 10.2 159,018 26,920 71 120.8 10.2 146,602 26,883 76 115.6 411 12.2 213,794 27,361 81 121.5 12.2 205,564 29,466 81 117.2 400 14.2 271,138 28,643 77 121.6 14.2 256,132 25,271 76 117.2 461 16.2 325,058 26,960 82 116.6 16.2 311,757 27,785 75 117.2 566 18.2 383,747 29,315 78 116.6 18.2 362,224 25,208 72 117.2 678 20.2 431,554 23,880 64 116.6 20.2 411,578 24,665 70 117.2 750 22.2 492,444 30,430 75 116.6 22.2 468,113 28,225 77 117.2 786 24.2 537,684 22,609 70 116.7 24.2 510,287 21,087 70 117.3 1,105 26.2 595,639 28,963 77 116.7 26.2 567,833 28,759 75 117.4 1,049 28.2 646,014 25,175 67 116.7 28.2 619,412 25,790 73 117.5 1,014 30.2 701,401 27,680 73 116.9 30.2 669,677 25,095 72 117.5 1,167 32.2 757,523 28,019 73 116.9 32.2 722,166 26,231 72 117.6 1,246 34.2 803,007 22,731 70 117.1 34.2 768,587 23,210 66 117.6 1,360 36.2 856,193 26,593 69 117.1 36.2 816,627 23,924 73 117.6 1,538 38.2 911,459 27,605 73 117.1 38.2 870,633 26,990 77 117.6 1,633 40.2 968,803 28,658 70 117.4 40.2 926,359 27,849 76 117.6 1,482 ---------------------- Sender ----------------------- --------------------- Receiver ---------------------- -------- Time [s] Count [m] Rate [m/s] CPU [%] RSS [M] Time [s] Count [m] Rate [m/s] CPU [%] RSS [M] Lat [ms] ----------------------------------------------------- ----------------------------------------------------- -------- 42.2 1,000,000 15,583 41 0.0 42.2 978,444 26,029 89 117.6 1,581 - - - - - 44.2 1,000,000 10,773 57 0.0 1,608 -------------------------------------------------------------------------------- Subject: qpid-jms amqp://broker-amq-amqp:5672/qpid-jms-over-ampq (/tmp/quiver-a1xz3nbz) Count: 1,000,000 messages Body size: 100 bytes Credit window: 1,000 messages Duration: 42.4 s Sender rate: 24,696 messages/s Receiver rate: 23,616 messages/s End-to-end rate: 23,573 messages/s Latencies by percentile: 0%: 1 ms 90.00%: 1575 ms 25%: 534 ms 99.00%: 1741 ms 50%: 988 ms 99.90%: 1886 ms 100%: 1929 ms 99.99%: 1926 ms --------------------------------------------------------------------------------&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h3 id="send-messages-to-amq-interconnect"&gt;Send messages to AMQ Interconnect&lt;/h3&gt; &lt;ol start="10" type="1"&gt; &lt;li&gt;Send 1,000,000 messages to the interconnect via the JMS client over AMQP protocol &lt;pre&gt;$ oc process -f https://raw.githubusercontent.com/ssorj/quiver/0.2.0/packaging/openshift/openshift-pod-template.yml \ DOCKER_IMAGE=$(oc get is quiver -o jsonpath='{.status.dockerImageRepository}'):latest \ DOCKER_CMD="[\"quiver\", \"amqp://amq-interconnect:5672/qpid-jms-over-ampq-via-interconnect\", \"--impl\", \"qpid-jms\", \"--verbose\"]" \ | oc create -f -&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Look at output for AMQP client pod &lt;pre&gt;$ oc get pods --watch $ oc logs -f {insert value of new pod name} ---------------------- Sender ----------------------- --------------------- Receiver ---------------------- -------- Time [s] Count [m] Rate [m/s] CPU [%] RSS [M] Time [s] Count [m] Rate [m/s] CPU [%] RSS [M] Lat [ms] ----------------------------------------------------- ----------------------------------------------------- -------- 2.2 1,529 764 131 102.6 2.2 1,465 731 120 84.5 21 4.2 12,580 5,514 151 116.2 4.2 12,529 5,526 138 114.5 16 6.2 42,121 14,756 125 119.5 6.2 41,815 14,606 90 111.3 6 8.2 85,563 21,721 82 119.9 8.2 85,028 21,596 71 111.7 4 10.2 125,149 19,773 75 120.2 10.2 124,858 19,905 62 112.0 5 12.2 169,899 22,264 79 116.5 12.2 169,965 22,486 67 112.1 5 14.3 212,816 21,437 69 116.7 14.2 212,442 21,217 60 112.1 5 16.3 259,889 23,536 75 116.7 16.2 259,571 23,553 71 114.7 4 18.3 308,674 24,332 86 119.1 18.2 308,723 24,539 69 114.9 4 20.3 340,342 15,826 67 119.1 20.2 340,176 15,726 58 115.0 6 22.3 386,804 23,208 76 119.3 22.2 386,597 23,199 67 115.0 4 24.3 434,611 23,880 75 119.3 24.2 434,435 23,895 65 115.0 4 26.3 472,270 18,783 63 119.4 26.2 471,754 18,650 53 115.0 6 28.3 507,116 17,406 59 119.4 28.2 506,646 17,420 51 115.0 6 30.3 541,841 17,345 57 119.4 30.2 541,639 17,488 56 115.1 6 32.3 577,421 17,781 61 119.4 32.2 576,429 17,352 50 115.1 6 34.3 612,512 17,528 61 119.4 34.2 612,231 17,892 53 115.1 6 36.3 644,913 16,192 58 119.5 36.2 644,190 15,972 48 115.1 6 38.3 678,782 16,901 58 119.5 38.2 678,577 17,176 52 115.1 7 40.3 714,240 17,720 60 119.5 40.2 713,569 17,487 51 115.3 6 ---------------------- Sender ----------------------- --------------------- Receiver ---------------------- -------- Time [s] Count [m] Rate [m/s] CPU [%] RSS [M] Time [s] Count [m] Rate [m/s] CPU [%] RSS [M] Lat [ms] ----------------------------------------------------- ----------------------------------------------------- -------- 42.3 750,187 17,965 62 119.5 42.2 748,967 17,672 51 115.3 6 44.3 787,234 18,496 63 119.5 44.3 787,500 19,171 55 115.3 6 46.3 820,124 16,420 58 119.5 46.3 819,155 15,820 48 115.3 6 48.3 856,316 18,087 59 119.5 48.3 855,868 18,338 51 115.3 6 50.3 897,520 20,551 68 119.5 50.3 897,232 20,641 57 115.3 5 52.3 944,594 23,537 73 119.5 52.3 944,159 23,452 63 115.3 4 54.3 990,567 22,986 72 119.5 54.3 990,176 22,997 64 115.3 4 56.3 1,000,000 4,716 17 0.0 56.3 1,000,000 4,907 15 0.0 4 -------------------------------------------------------------------------------- Subject: qpid-jms amqp://amq-interconnect:5672/qpid-jms-over-ampq-via-interconnect (/tmp/quiver-0sttx8_z) Count: 1,000,000 messages Body size: 100 bytes Credit window: 1,000 messages Duration: 53.7 s Sender rate: 18,615 messages/s Receiver rate: 18,634 messages/s End-to-end rate: 18,614 messages/s Latencies by percentile: 0%: 0 ms 90.00%: 10 ms 25%: 3 ms 99.00%: 18 ms 50%: 5 ms 99.90%: 43 ms 100%: 89 ms 99.99%: 72 ms --------------------------------------------------------------------------------&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h3 id="cleanup"&gt;Cleanup&lt;/h3&gt; &lt;ol start="12" type="1"&gt; &lt;li&gt;Cleanup and delete all quiver pods &lt;pre&gt;$ oc delete pod -l app=quiver&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2 id="does-your-client-use-another-language"&gt;Does your client use another language?&lt;/h2&gt; &lt;p&gt;If your language of choice was not shown in the demo, the good news is that Quiver supports several &lt;a href="https://github.com/ssorj/quiver#quiver-1"&gt;implementations&lt;/a&gt;. Here are some examples:&lt;/p&gt; &lt;pre&gt;$ oc process -f https://raw.githubusercontent.com/ssorj/quiver/0.2.0/packaging/openshift/openshift-pod-template.yml \ DOCKER_IMAGE=$(oc get is quiver -o jsonpath='{.status.dockerImageRepository}'):latest \ DOCKER_CMD="[\"quiver\", \"//broker-amq-tcp:61616/activemq-jms\", \"--impl\", \"activemq-jms\", \"--verbose\"]" \ | oc create -f - $ oc process -f https://raw.githubusercontent.com/ssorj/quiver/0.2.0/packaging/openshift/openshift-pod-template.yml \ DOCKER_IMAGE=$(oc get is quiver -o jsonpath='{.status.dockerImageRepository}'):latest \ DOCKER_CMD="[\"quiver\", \"//broker-amq-tcp:61616/qpid-messaging-cpp\", \"--impl\", \"qpid-messaging-cpp\", \"--verbose\"]" \ | oc create -f - $ oc process -f https://raw.githubusercontent.com/ssorj/quiver/0.2.0/packaging/openshift/openshift-pod-template.yml \ DOCKER_IMAGE=$(oc get is quiver -o jsonpath='{.status.dockerImageRepository}'):latest \ DOCKER_CMD="[\"quiver\", \"//broker-amq-tcp:61616/qpid-messaging-python\", \"--impl\", \"qpid-messaging-python\", \"--verbose\"]" \ | oc create -f - $ oc process -f https://raw.githubusercontent.com/ssorj/quiver/0.2.0/packaging/openshift/openshift-pod-template.yml \ DOCKER_IMAGE=$(oc get is quiver -o jsonpath='{.status.dockerImageRepository}'):latest \ DOCKER_CMD="[\"quiver\", \"//broker-amq-tcp:61616/qpid-proton-c\", \"--impl\", \"qpid-proton-c\", \"--verbose\"]" \ | oc create -f - $ oc process -f https://raw.githubusercontent.com/ssorj/quiver/0.2.0/packaging/openshift/openshift-pod-template.yml \ DOCKER_IMAGE=$(oc get is quiver -o jsonpath='{.status.dockerImageRepository}'):latest \ DOCKER_CMD="[\"quiver\", \"//broker-amq-tcp:61616/qpid-proton-cpp\", \"--impl\", \"qpid-proton-cpp\", \"--verbose\"]" \ | oc create -f - $ oc process -f https://raw.githubusercontent.com/ssorj/quiver/0.2.0/packaging/openshift/openshift-pod-template.yml \ DOCKER_IMAGE=$(oc get is quiver -o jsonpath='{.status.dockerImageRepository}'):latest \ DOCKER_CMD="[\"quiver\", \"//broker-amq-tcp:61616/qpid-proton-python\", \"--impl\", \"qpid-proton-python\", \"--verbose\"]" \ | oc create -f - $ oc process -f https://raw.githubusercontent.com/ssorj/quiver/0.2.0/packaging/openshift/openshift-pod-template.yml \ DOCKER_IMAGE=$(oc get is quiver -o jsonpath='{.status.dockerImageRepository}'):latest \ DOCKER_CMD="[\"quiver\", \"//broker-amq-tcp:61616/rhea\", \"--impl\", \"rhea\", \"--verbose\"]" \ | oc create -f -&lt;/pre&gt; &lt;h2 id="food-for-thought"&gt;Food for thought&lt;/h2&gt; &lt;p&gt;I hope this demo has shown how easy it is to use Quiver to interact with AMQ Broker and AMQ Interconnect on OCP.&lt;/p&gt; &lt;p&gt;It should have also raised questions around how Quiver could be integrated into your own systems. For example:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Could Quiver be part of your mvn integration tests?&lt;/li&gt; &lt;li&gt;Could Quiver be added as a stage within your CI/CD pipeline for smoke testing?&lt;/li&gt; &lt;li&gt;Could the results of the smoke test pass/fail the deployment?&lt;/li&gt; &lt;li&gt;Could Quiver be used as part of a heartbeat monitoring system to validate that the broker is alive?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These are several scenarios for which I see Quiver being highly useful, and you’ve probably thought of others.&lt;/p&gt; &lt;h3 id="disclaimer"&gt;&lt;a name="DISCLAIMER"&gt;&lt;/a&gt;Note&lt;/h3&gt; &lt;p&gt;[1] Although Quiver is developed by Red Hat employees, it is not supported under a Red Hat subscription and is strictly an upstream project.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fusing-quiver-with-amq-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=Using%20Quiver%20with%20AMQ%20on%20Red%20Hat%20OpenShift%20Container%20Platform" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fusing-quiver-with-amq-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=Using%20Quiver%20with%20AMQ%20on%20Red%20Hat%20OpenShift%20Container%20Platform" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fusing-quiver-with-amq-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=Using%20Quiver%20with%20AMQ%20on%20Red%20Hat%20OpenShift%20Container%20Platform" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fusing-quiver-with-amq-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=Using%20Quiver%20with%20AMQ%20on%20Red%20Hat%20OpenShift%20Container%20Platform" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fusing-quiver-with-amq-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=Using%20Quiver%20with%20AMQ%20on%20Red%20Hat%20OpenShift%20Container%20Platform" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fusing-quiver-with-amq-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=Using%20Quiver%20with%20AMQ%20on%20Red%20Hat%20OpenShift%20Container%20Platform" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fusing-quiver-with-amq-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=Using%20Quiver%20with%20AMQ%20on%20Red%20Hat%20OpenShift%20Container%20Platform" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fusing-quiver-with-amq-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=Using%20Quiver%20with%20AMQ%20on%20Red%20Hat%20OpenShift%20Container%20Platform" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F04%2F24%2Fusing-quiver-with-amq-on-red-hat-openshift-container-platform%2F&amp;#038;title=Using%20Quiver%20with%20AMQ%20on%20Red%20Hat%20OpenShift%20Container%20Platform" data-a2a-url="https://developers.redhat.com/blog/2019/04/24/using-quiver-with-amq-on-red-hat-openshift-container-platform/" data-a2a-title="Using Quiver with AMQ on Red Hat OpenShift Container Platform"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/24/using-quiver-with-amq-on-red-hat-openshift-container-platform/"&gt;Using Quiver with AMQ on Red Hat OpenShift Container Platform&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/l7ZAenG0X2k" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;As part of the Red Hat UKI Professional Services team, I have worked with several customers who are implementing AMQ Broker on Red Hat OpenShift Container Platform (OCP). One question customers typically ask is, “How do we validate that the AMQ configuration is correct for our scenario?” Previously, I would have suggested one of the [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/04/24/using-quiver-with-amq-on-red-hat-openshift-container-platform/"&gt;Using Quiver with AMQ on Red Hat OpenShift Container Platform&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2019/04/24/using-quiver-with-amq-on-red-hat-openshift-container-platform/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">588787</post-id><dc:creator>gahealy</dc:creator><dc:date>2019-04-24T07:00:57Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/04/24/using-quiver-with-amq-on-red-hat-openshift-container-platform/</feedburner:origLink></entry><entry><title>Red Hat Summit 2019: IT Automation and Management Labs Roadmap</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Nns4oHb0b6A/red-hat-summit-2019-it-automation-management-labs-roadmap.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="conference" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-red_hat_summit_2019_it_automation_and_management_labs_roadmap</id><updated>2019-04-24T05:00:05Z</updated><published>2019-04-24T05:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;a href="https://reg.summit.redhat.com/" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;" target="_blank"&gt;&lt;img border="0" data-original-height="389" data-original-width="769" height="161" src="https://1.bp.blogspot.com/-yX0WaXZmaTI/XJj8CSvWUlI/AAAAAAAAth4/4Z1aZQ7VOp061sKNZ-_kMauutZPP46AMgCLcBGAs/s320/Screenshot%2B2019-03-25%2Bat%2B17.04.08.png" width="320" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.redhat.com/en/summit/2019" target="_blank"&gt;Red Hat Summit 2019&lt;/a&gt; is rocking Boston, MA from May 7-9th in the &lt;a href="https://www.signatureboston.com/BCEC" target="_blank"&gt;Boston Convention and Exhibition Center&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Everything you need to know about the current state of open source enterprise ready software can be found at this event. From customers talking about their experiences leveraging open source in their solutions, to the creators of open source technologies you're using, and all the way down to hands-on lab experiences on these technologies.&lt;br /&gt;&lt;br /&gt;This hands-on appeal is what this series of articles is about. It's interesting to take a tour, so starting with this article let's examine a series of instructor-led labs based on a specific theme.&lt;br /&gt;&lt;br /&gt;This week it's a roadmap to &lt;i&gt;IT automation and management&lt;/i&gt; lab content.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;The following labs can be found in the&amp;nbsp;&lt;a href="https://summit.redhat.com/conference/sessions" target="_blank"&gt;session catalog online&lt;/a&gt;, by searching on title or filtering on &lt;i&gt;instructor-led labs&lt;/i&gt; and &lt;i&gt;IT automation and management.&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Ansible F5 automation workshop&lt;/h3&gt;&lt;i&gt;This is a hands-on lab from Red Hat and F5 Networks covering Red Hat Ansible Engine, Red Hat Ansible Tower, and F5 Networks BIG-IP. You'll get to automate and manage F5 BIG-IP nodes and build a web app on your own private workbench. Instructors will include network automation experts from F5 Networks and Red Hat Ansible. This session is geared toward those with limited or no experience in Ansible automation. The intended audience is any network engineer (various experience levels) or a system administrator with some very basic knowledge of F5 BIG-IP. New to F5 and just want to learn? No problem, this session will be beneficial to anyone willing to learn.&lt;br /&gt;&lt;br /&gt;Speakers: Colin McNaughton, Payal Singh, Sean Cavanaugh&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Deploy and scale Microsoft Azure infrastructures and applications with Red Hat Ansible Automation&lt;/h3&gt;&lt;i&gt;Immerse yourself in the world of Ansible by Red Hat and Microsoft Azure. Explore the vast Ansible module landscape for Azure and obtain hands-on experience deploying IaaS, PaaS and other infrastructures to Azure using Ansible playbooks. You'll receive the building blocks to extend your existing Ansible deployment to Azure and instructions on how to take advantage of both infrastructure and platform services. You'll perform the following entirely from Ansible Playbooks:&lt;br /&gt;&lt;/i&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;Create a Red Hat Enterprise Linux virtual machine in Azure using the Azure Marketplace.&lt;/i&gt;&lt;/li&gt;&lt;i&gt;&lt;li&gt;Create and configure an Azure MySQL PaaS database.&lt;/li&gt;&lt;li&gt;Deploy an application on the Red Hat Enterprise Linux virtual machine which utilizes the Azure MySQL PaaS database.&lt;/li&gt;&lt;li&gt;Generalize the Red Hat Enterprise Linux virtual machine image to create a golden image template for group deployments.&lt;/li&gt;&lt;li&gt;Scale out the application to multiple servers using Azure virtual machine scale sets.&lt;/li&gt;&lt;li&gt;Create an application gateway &amp;amp; load balancer to front-end the deployed application.&lt;/li&gt;&lt;/i&gt;&lt;/ul&gt;&lt;i&gt;In addition, hands-on labs will be available to showcase:&lt;br /&gt;&lt;/i&gt;&lt;br /&gt;&lt;ul&gt;&lt;i&gt;&lt;li&gt;Big data workloads using Azure HDInsight.&lt;/li&gt;&lt;li&gt;High-performance computing using Azure virtual machine infiniband interconnects.&lt;/li&gt;&lt;li&gt;Launching an application in Azure Kubernetes Service (AKS).&lt;/li&gt;&lt;li&gt;Serverless applications using Azure functions.&lt;/li&gt;&lt;/i&gt;&lt;/ul&gt;&lt;i&gt;You'll be provided with access to an Azure subscription and will not require any Azure / Microsoft credentials. All content will be obtained from GitHub and will persist.&lt;br /&gt;&lt;br /&gt;Speakers: Stuart Kirk, Zim Kalinowski, Harold Wong&lt;/i&gt;&lt;br /&gt;&lt;h3&gt;From source to RPM in 120 minutes&lt;/h3&gt;&lt;i&gt;In this lab, we'll learn best practices for packaging software using the Red Hat Enterprise Linux native packaging format, RPM. We'll cover how to properly build software from source code into RPM packages, create RPM packages from pre-compiled binaries, and to automate RPM builds from source code version control systems (such as Git) for use in CI/DevOps environments. And finally, we'll hear tips and tricks from lessons learned, such as how to set up and work with pristine build environments and why such things are important to software packaging.&lt;br /&gt;&lt;br /&gt;Speakers: Adam Miller, Carl George, Rob Marti, Tom Sorensen&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Getting started with Ansible&lt;/h3&gt;&lt;i&gt;Ansible is a simple yet powerful IT automation engine for app deployment, configuration management, and orchestration that you can learn quickly. In this lab, after a brief introduction, you'll install Red Hat Ansible Automation and run the first commands. Then, we'll tackle some of the basic concepts, and you'll start to write your first playbooks. Along the way, you'll learn more advanced concepts, such as controlling task execution and templating.&lt;br /&gt;&lt;br /&gt;Speakers: Eric Lavarde, Goetz Rieger, Roland Wolters, Daniel Brintzinger&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Getting started with Red Hat Ansible Tower&lt;/h3&gt;&lt;i&gt;Red Hat Ansible Tower helps you centralize and control your IT infrastructure with a visual dashboard, role-based access control, job scheduling, and graphical inventory management. In this lab you'll start with configuring inventories and credentials, then learn how to integrate your playbooks. After configuring job templates, you'll run your first jobs using Ansible Tower. Finally, we'll show you how to give users without Ansible knowledge limited control of playbook execution and introduce you to the workflows feature. This lab is best for people who already have basic experience with Ansible.&lt;br /&gt;&lt;br /&gt;Speaker(s): Eric Lavarde, Goetz Rieger, Daniel Brintzinger, Roland Wolters&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Hands on with Red Hat Satellite 6.5&lt;/h3&gt;&lt;i&gt;In this lab, you'll be exposed to the latest version of Red Hat Satellite, which is 6.5. You'll be able to exercise new features and see how Satellite improves the management of Red Hat Enterprise Linux.&lt;br /&gt;&lt;br /&gt;Speakers: Amir Feferkuchen, Bryan Kearney, John Mitsch, Peter Ondrejka&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Hands-on integrated management lab&lt;/h3&gt;&lt;i&gt;This hands-on lab will give you experience with full integration of all Red Hat Management products and services: Red Hat Satellite, Red Hat Ansible Tower, Red Hat Insights, Red Hat CloudForms, Red Hat CloudForms for hybrid cloud management and multicloud OS management. You'll be provided a working environment and be walked through integrations and major use case functionality with each product or service.&lt;br /&gt;&lt;br /&gt;Speakers: Andrés Valero, Chris Short, John Spinks, Roland Wolters, William Nix&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Implementing proactive security and compliance automation and DevSecOps&lt;/h3&gt;&lt;i&gt;In this hands-on lab, you’ll learn how to implement security and compliance automation for the infrastructure, operations, and application across a hybrid environment using a combination of various Red Hat products. Specifically, you’ll use a combination of Red Hat’s management and automation products, Red Hat OpenShift Container Platform, and OpenSCAP to:&lt;br /&gt;&lt;/i&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;Perform automated audit scans to quickly detect and automatically remediate security and compliance issues in a controlled way to ensure compliance against regulatory or custom profiles and for automated configuration compliance.&lt;/i&gt;&lt;/li&gt;&lt;i&gt;&lt;li&gt;Implement automated web application hardening.&lt;/li&gt;&lt;li&gt;Automatically provision a security-compliant host.&lt;/li&gt;&lt;li&gt;Implement infrastructure, security, and compliance as code.&lt;/li&gt;&lt;li&gt;Implement consistent and automated patch and configuration management.&lt;/li&gt;&lt;li&gt;Proactively identify and remediate security threats at scale with predictive analytics.&lt;/li&gt;&lt;li&gt;Have centralized management of your hybrid infrastructure for continuous security and monitoring.&lt;/li&gt;&lt;li&gt;Build security into your application by implementing DevSecOps at scale using Red Hat OpenShift Container Platform and several other tools, such as OWASP ZAP, SonarQube, Clair, and more to build a secure CI/CD application pipeline.&lt;/li&gt;&lt;/i&gt;&lt;/ul&gt;&lt;i&gt;Speakers: Lucy Kerner, Justin Lacey, Kevin Holmes, Khary Mendez, Will Tome&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Red Hat Ansible Tower for advanced users&lt;/h3&gt;&lt;i&gt;Have you started using Red Hat Ansible Tower, already love it, and want to know more? Then this lab is for you.&amp;nbsp;&lt;/i&gt;&lt;i&gt;You know the basics, so we'll give you a hands-on introduction to the more advanced concepts and features. We'll start by learning and exploring Ansible Tower clustering and how to use it for high availability and load balancing. Next, we'll cover the isolated node feature, which allows you to automate hosts in separate networks with limited access. You already know about inventories, so we'll step it up a bit by introducing you to dynamic inventories and the smart inventory feature. Along the way, you'll learn how to organize your Ansible roles and content in well-structured Git repositories. And finally, we'll cover using the API to expose even more ways to take advantage of Ansible Tower's power.&lt;/i&gt;&lt;br /&gt;&lt;i&gt;&lt;br /&gt;Speakers: Eric Lavarde, Goetz Rieger, Daniel Brintzinger, Roland Wolters&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;Stay tuned for more articles with insights into other themes that might interest you enough to register for one of these instructor-led labs at Red Hat Summit 2019.&lt;br /&gt;&lt;br /&gt;Looking forward to seeing you there!&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZqUDndC2yO4:1QCsHPN63Qk:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZqUDndC2yO4:1QCsHPN63Qk:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZqUDndC2yO4:1QCsHPN63Qk:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=ZqUDndC2yO4:1QCsHPN63Qk:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZqUDndC2yO4:1QCsHPN63Qk:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=ZqUDndC2yO4:1QCsHPN63Qk:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZqUDndC2yO4:1QCsHPN63Qk:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=ZqUDndC2yO4:1QCsHPN63Qk:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZqUDndC2yO4:1QCsHPN63Qk:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZqUDndC2yO4:1QCsHPN63Qk:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=ZqUDndC2yO4:1QCsHPN63Qk:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/ZqUDndC2yO4" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Nns4oHb0b6A" height="1" width="1" alt=""/&gt;</content><summary>Red Hat Summit 2019 is rocking Boston, MA from May 7-9th in the Boston Convention and Exhibition Center. Everything you need to know about the current state of open source enterprise ready software can be found at this event. From customers talking about their experiences leveraging open source in their solutions, to the creators of open source technologies you're using, and all the way down to ha...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2019-04-24T05:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/ZqUDndC2yO4/red-hat-summit-2019-it-automation-management-labs-roadmap.html</feedburner:origLink></entry><entry><title>Keycloak Releases and Versioning</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/K_l34VVomts/versioning.html" /><category term="feed_group_name_keycloak" scheme="searchisko:content:tags" /><category term="feed_name_keycloak" scheme="searchisko:content:tags" /><author><name>Stian Thorgersen</name></author><id>searchisko:content:id:jbossorg_blog-keycloak_releases_and_versioning</id><updated>2019-04-24T00:00:00Z</updated><published>2019-04-24T00:00:00Z</published><content type="html">&lt;p&gt; We are aiming to achieve a continuous delivery model with Keycloak. By that we mean it should be seamless to upgrade between Keycloak releases and to keep up to date with the latest release. &lt;/p&gt; &lt;p&gt; This requires no breaking changes, but rather deprecating old APIs allowing time to migrate to new APIs. &lt;/p&gt; &lt;p&gt; Traditional semantic versioning does not fit very well with this model. By following the mantra of continuous delivery we would forever be stuck on a major version and only update the minor version, and you could argue whether or not it would be correct to update the major version when an API that has been deprecated for a long period of time is removed. &lt;/p&gt; &lt;p&gt; With this in mind, we have made some slight changes to our release cadence and versioning schema. &lt;/p&gt; &lt;p&gt; For now, we will have a new feature release roughly 4 times each year. Each release will bump the major version number. That doesn't mean there are breaking changes, but until we perfect our continuous delivery model there may be some, so always refer to the migration guide prior to upgrading! &lt;/p&gt; &lt;p&gt; We have also decided to drop the Final suffix from releases. That is simply because it is not needed as we have not done any beta or release candidates for a long time. In the spirit of continuous delivery, we will have individual features marked as preview rather than whole releases. &lt;/p&gt; &lt;p&gt; As a final note, with the reduced release cadence we are planning to do more micro releases. This will be focused on critical bugs and security vulnerabilities. However, we may accept contributions to less critical bugs given the fix is well tested and has low risk of regressions. &lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/K_l34VVomts" height="1" width="1" alt=""/&gt;</content><summary>We are aiming to achieve a continuous delivery model with Keycloak. By that we mean it should be seamless to upgrade between Keycloak releases and to keep up to date with the latest release. This requires no breaking changes, but rather deprecating old APIs allowing time to migrate to new APIs. Traditional semantic versioning does not fit very well with this model. By following the mantra of conti...</summary><dc:creator>Stian Thorgersen</dc:creator><dc:date>2019-04-24T00:00:00Z</dc:date><feedburner:origLink>https://www.keycloak.org/2019/04/versioning.html</feedburner:origLink></entry></feed>
